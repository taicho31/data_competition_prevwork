{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "- change tag and classification rules\n",
    "- focus on xgboost\n",
    "- modify error\n",
    "- https://www.kaggle.com/meaninglesslives/using-decision-trees-for-arc\n",
    "- https://www.kaggle.com/davidbnn92/task-tagging\n",
    "- https://www.kaggle.com/nxrprime/grid-search-with-xgboost-and-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import permutations\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "test_path = data_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(task, index): # modify mistakes in data\n",
    "    # 025d127b\n",
    "    if index == \"025d127b.json\":\n",
    "        for i in range(9, 12):\n",
    "            for j in range(3, 8):\n",
    "                task['train'][0]['output'][i][j] = 0\n",
    "        for i in range(7, 10):\n",
    "            for j in range(3, 6):\n",
    "                task['train'][0]['output'][i][j] = 2\n",
    "        task['train'][0]['output'][8][4] = 0\n",
    "    # ef135b50\n",
    "    elif index == \"ef135b50.json\":\n",
    "        task['test'][0]['output'][6][4] = 9\n",
    "    # bd14c3bf\n",
    "    elif index == \"bd14c3bf.json\":\n",
    "        for i in range(3):\n",
    "            for j in range(5):\n",
    "                if task['test'][0]['input'][i][j] == 1:\n",
    "                    task['test'][0]['input'][i][j] = 2\n",
    "    # a8610ef7\n",
    "    elif index == \"a8610ef7.json\":\n",
    "        for i in range(6):\n",
    "            for j in range(6):\n",
    "                if task['test'][0]['output'][i][j] == 8:\n",
    "                    task['test'][0]['output'][i][j] = 5\n",
    "        task['train'][3]['input'][0][1] = 2\n",
    "        task['train'][3]['input'][5][1] = 2\n",
    "    # 54db823b\n",
    "    elif index == \"54db823b.json\":\n",
    "        task['train'][0]['output'][2][3] = 3\n",
    "        task['train'][0]['output'][2][4] = 9\n",
    "    # e5062a87\n",
    "    elif index == \"e5062a87.json\":\n",
    "        for j in range(3, 7):\n",
    "            task['train'][1]['output'][1][j] = 2\n",
    "    # 1b60fb0c\n",
    "    elif index == \"1b60fb0c.json\":\n",
    "        task['train'][1]['output'][8][8] = 0\n",
    "        task['train'][1]['output'][8][9] = 0\n",
    "    # 82819916\n",
    "    elif index == \"82819916.json\":\n",
    "        task['train'][0]['output'][4][5] = 4\n",
    "    # fea12743\n",
    "    elif index == \"fea12743.json\":\n",
    "        for i in range(11, 16):\n",
    "            for j in range(6):\n",
    "                if task['train'][0]['output'][i][j] == 2:\n",
    "                    task['train'][0]['output'][i][j] = 8\n",
    "    # 42a50994\n",
    "    elif index == \"42a50994.json\":\n",
    "        task['train'][0]['output'][1][0] = 8\n",
    "        task['train'][0]['output'][0][1] = 8\n",
    "    # f8be4b64\n",
    "    elif index == \"f8be4b64.json\":\n",
    "        for j in range(19):\n",
    "            if task['test'][0]['output'][12][j] == 0:\n",
    "                task['test'][0]['output'][12][j] = 1\n",
    "        task['test'][0]['output'][12][8] = 0\n",
    "    # d511f180\n",
    "    elif index == \"d511f180.json\":\n",
    "        task['train'][1]['output'][2][2] = 9\n",
    "    # 10fcaaa3\n",
    "    elif index == \"10fcaaa3.json\":\n",
    "        task['train'][1]['output'][4][7] = 8\n",
    "    # cbded52d\n",
    "    elif index == \"cbded52d.json\":\n",
    "        task['train'][0]['input'][4][6] = 1\n",
    "    # 11852cab\n",
    "    elif index == \"11852cab.json\":\n",
    "        task['train'][0]['input'][1][2] = 3\n",
    "    # 868de0fa\n",
    "    elif index == \"868de0fa.json\":\n",
    "        for j in range(2, 9):\n",
    "            task['train'][2]['input'][9][j] = 0\n",
    "            task['train'][2]['input'][10][j] = 1\n",
    "            task['train'][2]['input'][15][j] = 0\n",
    "            task['train'][2]['input'][16][j] = 1\n",
    "        task['train'][2]['input'][15][2] = 1\n",
    "        task['train'][2]['input'][15][8] = 1\n",
    "    # 6d58a25d\n",
    "    elif index == \"6d58a25d.json\":\n",
    "        task['train'][0]['output'][10][0] = 0\n",
    "        task['train'][2]['output'][6][13] = 4\n",
    "    # a9f96cdd\n",
    "    elif index == \"a9f96cdd.json\":\n",
    "        task['train'][3]['output'][1][3] = 0\n",
    "    # 48131b3c\n",
    "    elif index == \"48131b3c.json\":\n",
    "        task['train'][2]['output'][4][4] = 0\n",
    "    # 150deff5\n",
    "    elif index == \"150deff5.json\":\n",
    "        aux = task['train'][2]['output'].copy()\n",
    "        task['train'][2]['output'] = task['train'][2]['input'].copy()\n",
    "        task['train'][2]['input'] = aux\n",
    "    # 17cae0c1\n",
    "    elif index == \"17cae0c1.json\":\n",
    "        for i in range(3):\n",
    "            for j in range(3, 6):\n",
    "                task['test'][0]['output'][i][j] = 9\n",
    "    # e48d4e1a\n",
    "    elif index == \"e48d4e1a.json\":\n",
    "        task['train'][3]['input'][0][9] = 5\n",
    "        task['train'][3]['output'][0][9] = 0\n",
    "    # 8fbca751\n",
    "    elif index == \"8fbca751.json\":\n",
    "        task['train'][1]['output'][1][3] = 2\n",
    "        task['train'][1]['output'][2][3] = 8\n",
    "    # 4938f0c2\n",
    "    elif index == \"4938f0c2.json\":\n",
    "        for i in range(12):\n",
    "            for j in range(6,13):\n",
    "                if task['train'][2]['input'][i][j]==2:\n",
    "                    task['train'][2]['input'][i][j] = 0\n",
    "        for i in range(5,11):\n",
    "            for j in range(7):\n",
    "                if task['train'][2]['input'][i][j]==2:\n",
    "                    task['train'][2]['input'][i][j] = 0\n",
    "    # 9aec4887\n",
    "    elif index == \"9aec4887.json\":\n",
    "        task['train'][0]['output'][1][4] = 8\n",
    "    # b0f4d537\n",
    "    elif index == \"b0f4d537.json\":\n",
    "        for i in range(9):\n",
    "            task['train'][0]['output'][i][3] = 0\n",
    "            task['train'][0]['output'][i][4] = 1\n",
    "        task['train'][0]['output'][2][3] = 3\n",
    "        task['train'][0]['output'][2][4] = 3\n",
    "        task['train'][0]['output'][5][3] = 2\n",
    "    # aa300dc3\n",
    "    elif index == \"aa300dc3.json\":\n",
    "        task['train'][1]['input'][1][7] = 5\n",
    "        task['train'][1]['output'][1][7] = 5\n",
    "        task['train'][1]['input'][8][2] = 5\n",
    "        task['train'][1]['output'][8][2] = 5\n",
    "    # ad7e01d0\n",
    "    elif index == \"ad7e01d0.json\":\n",
    "        task['train'][0]['output'][6][7] = 0\n",
    "    # a8610ef7\n",
    "    elif index == \"a8610ef7.json\":\n",
    "        task['train'][3]['input'][0][1] = 0\n",
    "        task['train'][3]['input'][5][1] = 0\n",
    "        task['train'][3]['output'][0][1] = 0\n",
    "        task['train'][3]['output'][5][1] = 0\n",
    "    # 97239e3d\n",
    "    elif index == \"97239e3d.json\":\n",
    "        task['test'][0]['input'][14][6] = 0\n",
    "        task['test'][0]['input'][14][10] = 0\n",
    "    # d687bc17\n",
    "    elif index == \"d687bc17.json\":\n",
    "        task['train'][2]['output'][7][1] = 4\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# task tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_check(color_list):\n",
    "    tmp = color_list[0]\n",
    "    for i in range(1,len(color_list)):\n",
    "        if set(tmp) != set(color_list[i]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def create_df(folder_path):\n",
    "    task_names_list = sorted(os.listdir(folder_path))\n",
    "    task_list = []\n",
    "    for task_name in task_names_list: \n",
    "        task_file = str(folder_path / task_name)\n",
    "        with open(task_file, 'r') as f:\n",
    "            task = json.load(f)\n",
    "            if \"test\" not in str(folder_path):\n",
    "                task = preprocess(task, task_name)\n",
    "            task_list.append(task)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['task_name'] = task_names_list\n",
    "    df['task'] = task_list\n",
    "    df['number_of_train_pairs'] = df['task'].apply(lambda x: len(x['train']))\n",
    "    df['number_of_test_pairs'] = df['task'].apply(lambda x: len(x['test']))\n",
    "    \n",
    "    # Compare image sizes\n",
    "    df['inputs_all_have_same_height'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['input']) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['inputs_all_have_same_width'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['input'][0]) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['inputs_all_have_same_shape'] = df['inputs_all_have_same_height'] * df['inputs_all_have_same_width']\n",
    "    df['input_height_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['input'])\n",
    "                     if (len(set([len(example['input']) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['input_width_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['input'][0])\n",
    "                     if (len(set([len(example['input'][0]) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['outputs_all_have_same_height'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['output']) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['outputs_all_have_same_width'] = df['task'].apply(\n",
    "        lambda task: int(len(set([len(example['output'][0]) for example in task['train']])) == 1)\n",
    "    )\n",
    "    df['outputs_all_have_same_shape'] = df['outputs_all_have_same_height'] * df['outputs_all_have_same_width']\n",
    "    df['output_height_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output'])\n",
    "                     if (len(set([len(example['output']) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['output_width_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output'][0])\n",
    "                     if (len(set([len(example['output'][0]) for example in task['train']])) == 1)\n",
    "                     else np.nan\n",
    "    )  \n",
    "    df['in_each_pair_shape_doesnt_change'] = df['task'].apply(\n",
    "        lambda task: np.prod([int(len(example['input'][0])==len(example['output'][0])\n",
    "                                  and len(example['input'])==len(example['output'])\n",
    "                                 ) for example in task['train']\n",
    "                            ])\n",
    "    )\n",
    "    df['in_each_pair_shape_ratio_is_the_same'] = df['task'].apply(\n",
    "        lambda task: (len(set([len(example['input'][0]) / len(example['output'][0])\n",
    "                                 for example in task['train']]))==1) * (\n",
    "                      len(set([len(example['input']) / len(example['output'])\n",
    "                                 for example in task['train']]))==1)\n",
    "    )\n",
    "    df['o/i_height_ratio_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output']) / len(task['train'][0]['input'])\n",
    "                     if (len(set([len(example['input']) / len(example['output'])\n",
    "                                 for example in task['train']]))==1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    df['o/i_width_ratio_if_constant'] = df['task'].apply(\n",
    "        lambda task: len(task['train'][0]['output'][0]) / len(task['train'][0]['input'][0])\n",
    "                     if (len(set([len(example['input'][0]) / len(example['output'][0])\n",
    "                                 for example in task['train']]))==1)\n",
    "                     else np.nan\n",
    "    )\n",
    "    \n",
    "    # my idea ---------\n",
    "    # **\n",
    "    df[\"input_color_change_or_not\"] = df['task'].apply(lambda task: color_check([list(np.unique(np.array(example['input']))) for example in task[\"train\"]] ))\n",
    "    # **\n",
    "    df['color_kind_increase'] = df['task'].apply(\n",
    "        lambda task: np.all([len(np.unique(np.array(example['input']))) < len(np.unique(np.array(example['output']))) for example in task['train']]))\n",
    "    df['color_kind_decrease'] = df['task'].apply(\n",
    "        lambda task: np.all([len(np.unique(np.array(example['input']))) > len(np.unique(np.array(example['output']))) for example in task['train']]))\n",
    "    return df\n",
    "\n",
    "training_descriptive_df = create_df(training_path)\n",
    "evaluation_descriptive_df = create_df(evaluation_path)\n",
    "test_descriptive_df = create_df(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(row):\n",
    "    # same shape and color doesn't change in input and color kind decrease\n",
    "    if row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==1 and row.color_kind_decrease==1:\n",
    "        return 1\n",
    "    # same shape and color doesn't change in input and color kind increase\n",
    "    elif row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==1 and row.color_kind_increase==1:\n",
    "        return 2\n",
    "    # same shape and color doesn't change in input and color kind same\n",
    "    elif row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==1 and row.color_kind_increase==0  and row.color_kind_decrease==0:\n",
    "        return 3\n",
    "    # same shape and decrease color sum â†’ xgboost\n",
    "    if row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==0 and row.color_kind_decrease==1:\n",
    "        return 4\n",
    "    # different shape and decrease color sum\n",
    "    if row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==0 and row.color_kind_increase==1:\n",
    "        return 5\n",
    "    # different shape and increase color sum\n",
    "    elif row[\"in_each_pair_shape_doesnt_change\"] == 1 and row[\"o/i_height_ratio_if_constant\"] ==1 and row[\"o/i_width_ratio_if_constant\"]==1 and row.input_color_change_or_not==0 and row.color_kind_increase==0  and row.color_kind_decrease==0:\n",
    "        return 6\n",
    "    # otherwise\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "training_descriptive_df[\"class\"] = training_descriptive_df.apply(lambda x: classification(x), axis=1)\n",
    "evaluation_descriptive_df[\"class\"] = evaluation_descriptive_df.apply(lambda x: classification(x), axis=1)\n",
    "test_descriptive_df[\"class\"] = test_descriptive_df.apply(lambda x: classification(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training_descriptive_df[\"class\"].value_counts(normalize=True))\n",
    "#print(evaluation_descriptive_df[\"class\"].value_counts(normalize=True))\n",
    "#print(test_descriptive_df[\"class\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# feature engineering and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours(color, cur_row, cur_col, nrows, ncols, radius):\n",
    "\n",
    "    if cur_row<=radius-1: top = -1\n",
    "    else: top = color[cur_row-radius][cur_col]\n",
    "        \n",
    "    if cur_row>=nrows-radius: bottom = -1\n",
    "    else: bottom = color[cur_row+radius][cur_col]\n",
    "        \n",
    "    if cur_col<=radius-1: left = -1\n",
    "    else: left = color[cur_row][cur_col-radius]\n",
    "        \n",
    "    if cur_col>=ncols-radius: right = -1\n",
    "    else: right = color[cur_row][cur_col+radius]\n",
    "        \n",
    "    return top, bottom, left, right\n",
    "\n",
    "def get_tl_tr(color, cur_row, cur_col, nrows, ncols, radius):\n",
    "        \n",
    "    if cur_row<=radius-1:\n",
    "        top_left = -1\n",
    "        top_right = -1\n",
    "    else:\n",
    "        if cur_col<=radius-1: top_left=-1\n",
    "        else: top_left = color[cur_row-radius][cur_col-radius]\n",
    "        if cur_col>=ncols-radius: top_right=-1\n",
    "        else: top_right = color[cur_row-radius][cur_col+radius]   \n",
    "        \n",
    "    return top_left, top_right\n",
    "\n",
    "def get_bl_br(color, cur_row, cur_col, nrows, ncols, radius):\n",
    "        \n",
    "    if cur_row>=nrows-radius:\n",
    "        bottom_left = -1\n",
    "        bottom_right = -1\n",
    "    else:\n",
    "        if cur_col<=radius-1: bottom_left=-1\n",
    "        else: bottom_left = color[cur_row+radius][cur_col-radius]\n",
    "        if cur_col>=ncols-radius: bottom_right=-1\n",
    "        else: bottom_right = color[cur_row+radius][cur_col+radius]   \n",
    "        \n",
    "    return bottom_left, bottom_right\n",
    "\n",
    "def diagonal(color, cur_row, cur_col, nrows, ncols, direction):\n",
    "    element = []\n",
    "    element.append(color[cur_row, cur_col])\n",
    "    if direction == \"upper-right\":\n",
    "        for i in range(-nrows,nrows):\n",
    "            if (cur_row + i < nrows and cur_row +i >=0) and (cur_col - i < ncols and cur_col - i >=0):\n",
    "                element.append(color[cur_row+i][cur_col-i])\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        for i in range(-nrows,nrows):  \n",
    "            if (cur_row + i < nrows and cur_row +i >=0) and (cur_col + i < ncols and cur_col + i >=0):\n",
    "                element.append(color[cur_row+i][cur_col+i])\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    return np.array(element)\n",
    "\n",
    "def make_features(input_color, nfeat):\n",
    "    nrows, ncols = input_color.shape\n",
    "    feat = np.zeros((nrows*ncols,nfeat))\n",
    "    cur_idx = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            feat[cur_idx,0] = i\n",
    "            feat[cur_idx,1] = j\n",
    "            feat[cur_idx,2] = input_color[i][j]\n",
    "            feat[cur_idx,3:7] = neighbours(input_color, i, j, nrows, ncols,1)\n",
    "            feat[cur_idx,7:9] = get_tl_tr(input_color, i, j, nrows, ncols,1)\n",
    "            feat[cur_idx,9] = len(np.unique(input_color[i,:]))\n",
    "            feat[cur_idx,10] = len(np.unique(input_color[:,j]))\n",
    "            feat[cur_idx,11] = (i+j)\n",
    "            feat[cur_idx,12] = len(np.unique(input_color[i-1:i+1,j-1:j+1]))\n",
    "            feat[cur_idx,13:15] = get_bl_br(input_color, i, j, nrows, ncols,1)\n",
    "            feat[cur_idx,15] = np.sum(input_color[i,:])\n",
    "            feat[cur_idx,16] = np.sum(input_color[:,j])\n",
    "            feat[cur_idx,17:21] = neighbours(input_color, i, j, nrows, ncols,2)\n",
    "            feat[cur_idx,21] = np.max(input_color[i,:])\n",
    "            feat[cur_idx,22] = np.min(input_color[i,:])\n",
    "            feat[cur_idx,23] = np.max(input_color[:,j])\n",
    "            feat[cur_idx,24] = np.min(input_color[:,j])\n",
    "            feat[cur_idx,25:29] = neighbours(input_color, i, j, nrows, ncols,3)\n",
    "            feat[cur_idx,29] = np.sum(input_color[i-1:i+1,j-1:j+1])\n",
    "            feat[cur_idx,30] = np.sum(input_color[i-2:i+2,j-2:j+2])\n",
    "            feat[cur_idx,31] = len(input_color[i-5:i+5,j-5:j+5])\n",
    "            #feat[cur_idx,32] = np.sum(input_color[i+1,:]) if i+1<nrows else -1\n",
    "            #feat[cur_idx,33] = np.sum(input_color[i-1,:]) if i-1>0 else -1\n",
    "            #feat[cur_idx,34] = np.sum(input_color[:,j+1]) if j+1<ncols else -1\n",
    "            #feat[cur_idx,35] = np.sum(input_color[:,j-1]) if j-1>0 else -1     \n",
    "            cur_idx += 1\n",
    "        \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(task, mode='train'):\n",
    "    num_train_pairs = len(task[mode])\n",
    "    feat, target = [], []\n",
    "    \n",
    "    global local_neighb\n",
    "    for task_num in range(num_train_pairs):\n",
    "        input_color = np.array(task[mode][task_num]['input'])\n",
    "        target_color = task[mode][task_num]['output']\n",
    "        nrows, ncols = len(task[mode][task_num]['input']), len(task[mode][task_num]['input'][0])\n",
    "\n",
    "        target_rows, target_cols = len(task[mode][task_num]['output']), len(task[mode][task_num]['output'][0])\n",
    "        \n",
    "        if (target_rows!=nrows) or (target_cols!=ncols):\n",
    "            return None, None, 1\n",
    "\n",
    "        imsize = nrows*ncols\n",
    "        offset = imsize*task_num*3 #since we are using three types of aug\n",
    "        feat.extend(make_features(input_color, nfeat))\n",
    "        target.extend(np.array(target_color).reshape(-1,))\n",
    "            \n",
    "    return np.array(feat), np.array(target), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat = 32\n",
    "local_neighb = 5\n",
    "def data_aug(tasks):\n",
    "    try:\n",
    "        tmp = []\n",
    "        for i in range(len(tasks)):\n",
    "            tmp1 = {'input': 0, 'output': 0}\n",
    "            tmp1[\"input\"], tmp1[\"output\"] = np.fliplr(tasks[i][\"input\"]).tolist(), np.fliplr(tasks[i][\"output\"]).tolist()\n",
    "            tmp2 = {'input': 0, 'output': 0}\n",
    "            tmp2[\"input\"], tmp2[\"output\"] = np.flipud(tasks[i][\"input\"]).tolist(), np.flipud(tasks[i][\"output\"]).tolist()\n",
    "            tmp3 = {'input': 0, 'output': 0}\n",
    "            tmp3[\"input\"], tmp3[\"output\"] = np.rot90(tasks[i][\"input\"]).tolist(), np.rot90(tasks[i][\"output\"]).tolist()\n",
    "            tmp4 = {'input': 0, 'output': 0}\n",
    "            tmp4[\"input\"], tmp4[\"output\"] = np.rot90(np.fliplr(tasks[i][\"input\"]),1).tolist(), np.rot90(np.fliplr(tasks[i][\"output\"]),1).tolist()\n",
    "            tmp5 = {'input': 0, 'output': 0}\n",
    "            tmp5[\"input\"], tmp5[\"output\"] = np.rot90(np.fliplr(tasks[i][\"input\"]),2).tolist(), np.rot90(np.fliplr(tasks[i][\"output\"]),2).tolist()\n",
    "            tmp6 = {'input': 0, 'output': 0}\n",
    "            tmp6[\"input\"], tmp6[\"output\"] = np.rot90(np.fliplr(tasks[i][\"input\"]),3).tolist(), np.rot90(np.fliplr(tasks[i][\"output\"]),3).tolist()\n",
    "            tmp7 = {'input': 0, 'output': 0}\n",
    "            tmp7[\"input\"], tmp7[\"output\"] = np.rot90(np.flipud(tasks[i][\"input\"]),1).tolist(), np.rot90(np.flipud(tasks[i][\"output\"]),1).tolist()\n",
    "            tmp8 = {'input': 0, 'output': 0}\n",
    "            tmp8[\"input\"], tmp8[\"output\"] = np.rot90(np.flipud(tasks[i][\"input\"]),2).tolist(),np.rot90(np.flipud(tasks[i][\"output\"]),2).tolist()\n",
    "            tmp9 = {'input': 0, 'output': 0}\n",
    "            tmp9[\"input\"], tmp9[\"output\"] =np.rot90(np.flipud(tasks[i][\"input\"]),3).tolist(),np.rot90(np.flipud(tasks[i][\"output\"]),3).tolist()\n",
    "            tmp10 = {'input': 0, 'output': 0}\n",
    "            tmp10[\"input\"], tmp10[\"output\"] = np.fliplr(np.flipud(tasks[i][\"input\"])).tolist(),np.fliplr(np.flipud(tasks[i][\"output\"])).tolist()\n",
    "            tmp11 = {'input': 0, 'output': 0}\n",
    "            tmp11[\"input\"], tmp11[\"output\"] = np.flipud(np.fliplr(tasks[i][\"input\"])).tolist(),np.flipud(np.fliplr(tasks[i][\"output\"])).tolist()\n",
    "            tmp.append(tmp1)\n",
    "            tmp.append(tmp2)\n",
    "            tmp.append(tmp3)\n",
    "            tmp.append(tmp4)\n",
    "            tmp.append(tmp5)\n",
    "            tmp.append(tmp6)\n",
    "            tmp.append(tmp7)\n",
    "            tmp.append(tmp8)\n",
    "            tmp.append(tmp9)\n",
    "            tmp.append(tmp10)\n",
    "            tmp.append(tmp11)\n",
    "        for i in tmp:\n",
    "            tasks.append(i)\n",
    "        return tasks\n",
    "    except:\n",
    "        return tasks\n",
    "\n",
    "def data_aug2(a):\n",
    "    try:\n",
    "        flg = 0\n",
    "        new_data = []\n",
    "        for job in a:\n",
    "            color = [i for i in np.unique(np.array(job[\"input\"])) if i != 0]\n",
    "            color_out = [i for i in np.unique(np.array(job[\"output\"])) if i != 0]\n",
    "            if set(color) == set(color_out):\n",
    "                color_pos = []\n",
    "                color_posout = []\n",
    "                for i in color: # for input\n",
    "                    tmp = np.argwhere(np.array(job[\"input\"])==i).tolist()\n",
    "                    color_pos.append(tmp)\n",
    "                for i in color: # for output\n",
    "                    tmp = np.argwhere(np.array(job[\"output\"])==i).tolist()\n",
    "                    color_posout.append(tmp)\n",
    "                ind = [j for j in range(len(color))]\n",
    "                for i,ele in enumerate(permutations(ind)):\n",
    "                    if i != 0:\n",
    "                        tmp1 = np.copy(job[\"input\"])\n",
    "                        for c in range(len(ele)):\n",
    "                            for pos in color_pos[ele[c]]:\n",
    "                                tmp1[pos[0],pos[1]] = color[c]\n",
    "                        tmp2 = np.copy(job[\"output\"])\n",
    "                        for c in range(len(ele)):\n",
    "                            for pos in color_posout[ele[c]]:\n",
    "                                tmp2[pos[0],pos[1]] = color[c]\n",
    "                        if len(new_data) >50:\n",
    "                            break\n",
    "                        new_data.append({\"input\":tmp1.tolist(), \"output\":tmp2.tolist()})\n",
    "            else:\n",
    "                return a\n",
    "        for i in new_data:\n",
    "            a.append(i)\n",
    "        return a\n",
    "    except:\n",
    "        return a\n",
    "\n",
    "def modelling(mode, kind):\n",
    "    print(mode)\n",
    "    count = 0\n",
    "    sample_sub = pd.read_csv(data_path/'sample_submission.csv')\n",
    "    sample_sub = sample_sub.set_index('output_id')\n",
    "    \n",
    "    valid_scores = {}\n",
    "    model_accuracies = {'ens': []}\n",
    "    pred_taskids = []\n",
    "    \n",
    "    if mode=='eval':\n",
    "        task_path = evaluation_path\n",
    "        df = evaluation_descriptive_df\n",
    "    elif mode=='train':\n",
    "        task_path = training_path\n",
    "        df = training_descriptive_df\n",
    "    elif mode=='test':\n",
    "        task_path = test_path\n",
    "        df = test_descriptive_df\n",
    "    all_task_ids = sorted(os.listdir(task_path))\n",
    "    # training ----------\n",
    "    for task_id in all_task_ids:\n",
    "        class_num = df[df.task_name==task_id][\"class\"].values[0]\n",
    "        task_file = str(task_path / task_id)\n",
    "        with open(task_file, 'r') as f:\n",
    "            task = json.load(f)\n",
    "        \n",
    "        if mode != \"test\":\n",
    "            task = preprocess(task, task_id)\n",
    "\n",
    "        if class_num == 1 or class_num==3 or class_num==5 or class_num==6:\n",
    "            _, _, not_valid = features(task)\n",
    "            if not_valid:\n",
    "                print('ignoring task', task_file)\n",
    "                count += 1\n",
    "                continue\n",
    "            \n",
    "            task[\"train\"] = data_aug2(task[\"train\"])\n",
    "            feat, target, _ = features(task)\n",
    "        elif class_num == 2 or class_num == 4:\n",
    "            _, _, not_valid = features(task)\n",
    "            if not_valid:\n",
    "                print('ignoring task', task_file)\n",
    "                count += 1\n",
    "                continue\n",
    "            \n",
    "            task[\"train\"] = data_aug(task[\"train\"])\n",
    "            feat, target, _ = features(task)\n",
    "        else:\n",
    "            feat, target, not_valid = features(task)\n",
    "            if not_valid:\n",
    "                print('ignoring task', task_file)\n",
    "                count += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "        if kind == \"xgb\":   \n",
    "            model = XGBClassifier(n_estimators=50, max_depth = 5, num_leaves=10, learning_rate=0.1, n_jobs=-1)\n",
    "        elif kind == \"lgb\":\n",
    "            model = LGBMClassifier(n_estimators=60, max_depth=5, min_child_samples=1, n_jobs=-1, learning_rate=0.25)\n",
    "        else:\n",
    "            model = CatBoostClassifier(n_estimators=70, max_depth = 6, min_child_samples=1, learning_rate=0.25)\n",
    "        model.fit(feat, target, verbose=0)\n",
    "    # training on input pairs is done ----------\n",
    "    \n",
    "    # test predictions begins here\n",
    "        num_test_pairs = len(task['test'])\n",
    "        for task_num in range(num_test_pairs):\n",
    "            cur_idx = 0\n",
    "            input_color = np.array(task['test'][task_num]['input'])\n",
    "            nrows, ncols = len(task['test'][task_num]['input']), len(task['test'][task_num]['input'][0])\n",
    "            feat = make_features(input_color, nfeat)\n",
    "            preds = model.predict(feat).reshape(nrows,ncols)\n",
    "        \n",
    "            if (mode=='train') or (mode=='eval'):\n",
    "                ens_acc = (np.array(task['test'][task_num]['output'])==preds).sum()/(nrows*ncols)\n",
    "                model_accuracies['ens'].append(ens_acc)\n",
    "                pred_taskids.append(f'{task_id[:-5]}_{task_num}')\n",
    "                print(str(class_num) + \", \" + str(task_id) + ' ensemble accuracy',(np.array(task['test'][task_num]['output'])==preds).sum()/(nrows*ncols))\n",
    "            else:\n",
    "                preds = preds.astype(int).tolist()\n",
    "                sample_sub.loc[f'{task_id[:-5]}_{task_num}','output'] = flattener(preds)\n",
    "    print(str(count)+\" tasks were ignored.\")\n",
    "    return sample_sub, model_accuracies, pred_taskids\n",
    "\n",
    "#_, train_xgb_accuracies, train_ids= modelling('train', 'xgb')\n",
    "#_, eval_xgb_accuracies, eval_ids  = modelling('eval', 'xgb')\n",
    "#_, train_lgb_accuracies, train_ids= modelling('train', 'lgb')\n",
    "#_, eval_lgb_accuracies, eval_ids  = modelling('eval', 'lgb')\n",
    "#_, train_cat_accuracies, train_ids= modelling('train', 'cat')\n",
    "#_, eval_cat_accuracies, eval_ids  = modelling('eval', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(train_xgb_accuracies, index=train_ids)\n",
    "#for c in df.columns:\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]==1).sum())\n",
    "#    print(df[df.loc[:, c]==1].index)\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]>0.9).sum())\n",
    "\n",
    "#df = pd.DataFrame(eval_xgb_accuracies, index=eval_ids)\n",
    "#for c in df.columns:\n",
    "#    print(f'for {c} no. of complete evaluation tasks is', (df.loc[:, c]==1).sum())\n",
    "#    print(df[df.loc[:, c]==1].index)\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]>0.9).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(train_lgb_accuracies, index=train_ids)\n",
    "#for c in df.columns:\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]==1).sum())\n",
    "#    print(df[df.loc[:, c]==1].index)\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]>0.9).sum())\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(eval_lgb_accuracies, index=eval_ids)\n",
    "#for c in df.columns:\n",
    "#    print(f'for {c} no. of complete evaluation tasks is', (df.loc[:, c]==1).sum())\n",
    "#    print(df[df.loc[:, c]==1].index)\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]>0.9).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(train_cat_accuracies, index=train_ids)\n",
    "#for c in df.columns:\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]==1).sum())\n",
    "#    print(df[df.loc[:, c]==1].index)\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]>0.9).sum())\n",
    "\n",
    "#df = pd.DataFrame(eval_cat_accuracies, index=eval_ids)\n",
    "#for c in df.columns:\n",
    "#    print(f'for {c} no. of complete evaluation tasks is', (df.loc[:, c]==1).sum())\n",
    "#    print(df[df.loc[:, c]==1].index)\n",
    "#    print(f'for {c} no. of complete training tasks is', (df.loc[:, c]>0.9).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/00576224.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0692e18c.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0934a4d8.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0a1d4ef5.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0bb8deee.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0c786b71.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/0c9aba6e.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/12997ef3.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/136b0064.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/15696249.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/195ba7dc.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/1990f7a8.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/19bb5feb.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/1a2e2828.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/1a6449f1.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/2037f2c7.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/2072aba6.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/20818e16.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/2697da3f.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/2753e76c.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/27f8ce4f.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/281123b4.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/2c0b0aff.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/2f0c5170.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/310f3251.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/3194b014.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/31d5ba1a.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/34b99a2b.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/351d6448.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/358ba94e.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/3979b1a8.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/3b4c2228.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/3d31c5b3.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/3ee1011a.json\n",
      "ignoring task /kaggle/input/abstraction-and-reasoning-challenge/test/414297c0.json\n",
      "35 tasks were ignored.\n"
     ]
    }
   ],
   "source": [
    "test_xgb, _, _ = modelling('test', 'xgb')\n",
    "test_xgb.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_sub = test_xgb.reset_index()\n",
    "#final_sub = final_sub.sort_values(by=\"output_id\")\n",
    "\n",
    "#test_lgb = test_lgb.sort_values(by=\"output_id\")\n",
    "#test_cat = test_cat.sort_values(by=\"output_id\")\n",
    "#out1 = final_sub[\"output\"].astype(str).values\n",
    "#out2 = test_lgb[\"output\"].astype(str).values\n",
    "#out3 = test_cat[\"output\"].astype(str).values\n",
    "\n",
    "#merge_output = []\n",
    "#for o1, o2, o3 in zip(out1, out2, out3):\n",
    "#    o = o1.strip().split(\" \")[:1] + o2.strip().split(\" \")[:1] + o2.strip().split(\" \")[:1]\n",
    "#    o = \" \".join(o[:3])\n",
    "#    merge_output.append(o)\n",
    "#final_sub[\"output\"] = merge_output\n",
    "#final_sub[\"output\"] = final_sub[\"output\"].astype(str)\n",
    "#final_sub.to_csv(\"submission.csv\", index=False)\n",
    "#final_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
