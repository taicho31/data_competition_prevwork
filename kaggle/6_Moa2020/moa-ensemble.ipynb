{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027353,
     "end_time": "2020-10-31T01:43:48.311677",
     "exception": false,
     "start_time": "2020-10-31T01:43:48.284324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- cancel xgb\n",
    "- add lstm\n",
    "- try weight optimization by each target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:43:48.371930Z",
     "iopub.status.busy": "2020-10-31T01:43:48.371016Z",
     "iopub.status.idle": "2020-10-31T01:43:58.805796Z",
     "shell.execute_reply": "2020-10-31T01:43:58.805071Z"
    },
    "papermill": {
     "duration": 10.466678,
     "end_time": "2020-10-31T01:43:58.805952",
     "exception": false,
     "start_time": "2020-10-31T01:43:48.339274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:43:58.881308Z",
     "iopub.status.busy": "2020-10-31T01:43:58.878066Z",
     "iopub.status.idle": "2020-10-31T01:45:33.854110Z",
     "shell.execute_reply": "2020-10-31T01:45:33.852971Z"
    },
    "papermill": {
     "duration": 95.018145,
     "end_time": "2020-10-31T01:45:33.854269",
     "exception": false,
     "start_time": "2020-10-31T01:43:58.836124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n",
    "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n",
    "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-31T01:45:51.867365Z",
     "iopub.status.busy": "2020-10-31T01:45:51.866327Z",
     "iopub.status.idle": "2020-10-31T01:46:03.055225Z",
     "shell.execute_reply": "2020-10-31T01:46:03.053882Z"
    },
    "papermill": {
     "duration": 11.233542,
     "end_time": "2020-10-31T01:46:03.055366",
     "exception": false,
     "start_time": "2020-10-31T01:45:51.821824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from category_encoders import CountEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "sys.path.append('../input/multilabelstraifier/')\n",
    "from ml_stratifiers import MultilabelStratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.optimize import minimize, fsolve\n",
    "import xgboost as xgb\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from cuml.svm import SVC, SVR\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "#from sklearn.kernel_approximation import Nystroem\n",
    "#from sklearn.isotonic import IsotonicRegression\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029056,
     "end_time": "2020-10-31T01:46:03.113989",
     "exception": false,
     "start_time": "2020-10-31T01:46:03.084933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:03.188901Z",
     "iopub.status.busy": "2020-10-31T01:46:03.187760Z",
     "iopub.status.idle": "2020-10-31T01:46:09.497372Z",
     "shell.execute_reply": "2020-10-31T01:46:09.496601Z"
    },
    "papermill": {
     "duration": 6.353768,
     "end_time": "2020-10-31T01:46:09.497520",
     "exception": false,
     "start_time": "2020-10-31T01:46:03.143752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/lish-moa/'\n",
    "train = pd.read_csv(DATA_DIR + 'train_features.csv')\n",
    "targets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:09.564180Z",
     "iopub.status.busy": "2020-10-31T01:46:09.562306Z",
     "iopub.status.idle": "2020-10-31T01:46:09.564952Z",
     "shell.execute_reply": "2020-10-31T01:46:09.565475Z"
    },
    "papermill": {
     "duration": 0.038598,
     "end_time": "2020-10-31T01:46:09.565622",
     "exception": false,
     "start_time": "2020-10-31T01:46:09.527024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_feats = [ i for i in targets.columns if i != \"sig_id\"]\n",
    "g_feats = [i for i in train.columns if \"g-\" in i]\n",
    "c_feats = [i for i in train.columns if \"c-\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:09.660354Z",
     "iopub.status.busy": "2020-10-31T01:46:09.659223Z",
     "iopub.status.idle": "2020-10-31T01:46:10.165047Z",
     "shell.execute_reply": "2020-10-31T01:46:10.165568Z"
    },
    "papermill": {
     "duration": 0.570733,
     "end_time": "2020-10-31T01:46:10.165758",
     "exception": false,
     "start_time": "2020-10-31T01:46:09.595025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cons_train_index = train[train.cp_type!=\"ctl_vehicle\"].index\n",
    "noncons_test_index = test[test.cp_type==\"ctl_vehicle\"].index\n",
    "cons_test_index = test[test.cp_type!=\"ctl_vehicle\"].index\n",
    "\n",
    "test = test[test.index.isin(cons_test_index)].reset_index(drop=True)\n",
    "train = train[train.index.isin(cons_train_index)].reset_index(drop=True)\n",
    "fn_targets = targets.drop(\"sig_id\", axis=1).copy()\n",
    "fn_targets = fn_targets[fn_targets.index.isin(cons_train_index)].copy().reset_index(drop=True).to_numpy()\n",
    "y = targets.drop(\"sig_id\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029668,
     "end_time": "2020-10-31T01:46:10.226257",
     "exception": false,
     "start_time": "2020-10-31T01:46:10.196589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:10.349073Z",
     "iopub.status.busy": "2020-10-31T01:46:10.330751Z",
     "iopub.status.idle": "2020-10-31T01:46:10.351885Z",
     "shell.execute_reply": "2020-10-31T01:46:10.351312Z"
    },
    "papermill": {
     "duration": 0.096228,
     "end_time": "2020-10-31T01:46:10.352002",
     "exception": false,
     "start_time": "2020-10-31T01:46:10.255774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_simple(df, remove_features):\n",
    "    tmp = df.copy()\n",
    "    tmp.loc[:, 'cp_dose'] = tmp.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    tmp.drop(remove_features, axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "def fe_xgb(df):\n",
    "    tmp = df.copy()\n",
    "    tmp['g_sum'] = tmp[g_feats].sum(axis = 1)\n",
    "    tmp['g_mean'] = tmp[g_feats].mean(axis = 1)\n",
    "    tmp['g_std'] = tmp[g_feats].std(axis = 1)\n",
    "    tmp['g_kurt'] = tmp[g_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[g_feats].skew(axis = 1)\n",
    "    tmp['c_sum'] = tmp[c_feats].sum(axis = 1)\n",
    "    tmp['c_mean'] = tmp[c_feats].mean(axis = 1)\n",
    "    tmp['c_std'] = tmp[c_feats].std(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[c_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[c_feats].skew(axis = 1)\n",
    "    tmp['gc_sum'] = tmp[c_feats + g_feats].sum(axis = 1)\n",
    "    tmp['gc_mean'] = tmp[c_feats + g_feats].mean(axis = 1)\n",
    "    tmp['gc_std'] = tmp[c_feats + g_feats].std(axis = 1)\n",
    "    tmp['gc_kurt'] = tmp[c_feats + g_feats].kurtosis(axis = 1)\n",
    "    tmp['gc_skew'] = tmp[c_feats + g_feats].skew(axis = 1)\n",
    "    return tmp\n",
    "\n",
    "def fe_mlp(df_train, df_test):\n",
    "    tmp_train = df_train.copy()\n",
    "    tmp_test = df_test.copy()\n",
    "    X = tmp_train.iloc[:,4:].copy().values\n",
    "    select = VarianceThreshold(threshold=0.7)\n",
    "    X_new = select.fit_transform(X)\n",
    "    drop_feats = list(np.array(tmp_train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "    \n",
    "    tmp_train.drop(drop_feats, axis=1, inplace=True)\n",
    "    tmp_test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "    modg_feats = [i for i in tmp_train.columns if \"g-\" in i]\n",
    "    modc_feats = [i for i in tmp_train.columns if \"c-\" in i]\n",
    "    \n",
    "    for i in modc_feats + modg_feats:\n",
    "        ss = preprocessing.QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution=\"normal\")\n",
    "        ss.fit(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_train[i] = ss.transform(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_test[i] = ss.transform(tmp_test[i].values.reshape(-1,1))\n",
    "    \n",
    "    c_num = 10\n",
    "    pca_c_cols = [\"pca-c\"+str(i+1) for i in range(c_num)]\n",
    "    pca = PCA(n_components=c_num,random_state=42)\n",
    "    c_train = pca.fit_transform(tmp_train[modc_feats])\n",
    "    c_test = pca.transform(tmp_test[modc_feats])\n",
    "    c_train = pd.DataFrame(c_train, columns=pca_c_cols)\n",
    "    c_test = pd.DataFrame(c_test, columns=pca_c_cols)\n",
    "\n",
    "    g_num = 60\n",
    "    pca_g_cols = [\"pca-g\"+str(i+1) for i in range(g_num)]\n",
    "    pca = PCA(n_components=g_num, random_state=42)\n",
    "    g_train = pca.fit_transform(tmp_train[modg_feats])\n",
    "    g_test = pca.transform(tmp_test[modg_feats])\n",
    "    g_train = pd.DataFrame(g_train, columns=pca_g_cols)\n",
    "    g_test = pd.DataFrame(g_test, columns=pca_g_cols)\n",
    "\n",
    "    tmp_train = pd.concat([tmp_train, c_train],axis=1)\n",
    "    tmp_test = pd.concat([tmp_test, c_test],axis=1)\n",
    "    tmp_train = pd.concat([tmp_train, g_train],axis=1)\n",
    "    tmp_test = pd.concat([tmp_test, g_test],axis=1)\n",
    "    \n",
    "    return tmp_train, tmp_test\n",
    "\n",
    "def fe_mlp2(df):\n",
    "    tmp = df.copy()\n",
    "    modg_feats = [i for i in tmp.columns if \"g-\" in i]\n",
    "    modc_feats = [i for i in tmp.columns if \"c-\" in i]\n",
    "    tmp['g_sum'] = tmp[modg_feats].sum(axis = 1)\n",
    "    tmp['g_mean'] = tmp[modg_feats].mean(axis = 1)\n",
    "    tmp['g_std'] = tmp[modg_feats].std(axis = 1)\n",
    "    tmp['g_kurt'] = tmp[modg_feats].kurtosis(axis = 1)\n",
    "    tmp['g_skew'] = tmp[modg_feats].skew(axis = 1)\n",
    "    tmp['c_sum'] = tmp[modc_feats].sum(axis = 1)\n",
    "    tmp['c_mean'] = tmp[modc_feats].mean(axis = 1)\n",
    "    tmp['c_std'] = tmp[modc_feats].std(axis = 1)\n",
    "    tmp['c_kurt'] = tmp[modc_feats].kurtosis(axis = 1)\n",
    "    tmp['c_skew'] = tmp[modc_feats].skew(axis = 1)\n",
    "    tmp['gc_sum'] = tmp[modc_feats + modg_feats].sum(axis = 1)\n",
    "    tmp['gc_mean'] = tmp[modc_feats + modg_feats].mean(axis = 1)\n",
    "    tmp['gc_std'] = tmp[modc_feats + modg_feats].std(axis = 1)\n",
    "    tmp['gc_kurt'] = tmp[modc_feats + modg_feats].kurtosis(axis = 1)\n",
    "    tmp['gc_skew'] = tmp[modc_feats + modg_feats].skew(axis = 1)\n",
    "    tmp = pd.get_dummies(tmp, columns=['cp_time','cp_dose'])\n",
    "    tmp.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True) \n",
    "    return tmp\n",
    "\n",
    "def fe_tabnet(df_train, df_test):\n",
    "    tmp_train = df_train.copy()\n",
    "    tmp_test = df_test.copy()\n",
    "    X = tmp_train.iloc[:,4:].copy().values\n",
    "    select = VarianceThreshold(threshold=0.7)\n",
    "    X_new = select.fit_transform(X)\n",
    "    drop_feats = list(np.array(tmp_train.iloc[:,4:].columns)[select.get_support()==False])\n",
    "    \n",
    "    tmp_train.drop(drop_feats, axis=1, inplace=True)\n",
    "    tmp_test.drop(drop_feats, axis=1, inplace=True)\n",
    "\n",
    "    modg_feats = [i for i in tmp_train.columns if \"g-\" in i]\n",
    "    modc_feats = [i for i in tmp_train.columns if \"c-\" in i]\n",
    "    \n",
    "    for i in modc_feats + modg_feats:\n",
    "        ss = preprocessing.QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution=\"normal\")\n",
    "        ss.fit(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_train[i] = ss.transform(tmp_train[i].values.reshape(-1,1))\n",
    "        tmp_test[i] = ss.transform(tmp_test[i].values.reshape(-1,1))\n",
    "        \n",
    "    tmp_train = pd.get_dummies(tmp_train, columns=['cp_time','cp_dose'])\n",
    "    tmp_train.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    tmp_test = pd.get_dummies(tmp_test, columns=['cp_time','cp_dose'])\n",
    "    tmp_test.drop([\"cp_type\", \"sig_id\"], axis=1, inplace=True)\n",
    "    return tmp_train, tmp_test\n",
    "\n",
    "def fe_lstm(df):\n",
    "    tmp = df.copy()    \n",
    "    tmp.drop([\"cp_type\", \"sig_id\", \"cp_dose\", \"cp_time\"], axis=1, inplace=True)\n",
    "    return tmp\n",
    "\n",
    "remove_features = [\"cp_type\" , \"sig_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:10.421274Z",
     "iopub.status.busy": "2020-10-31T01:46:10.418625Z",
     "iopub.status.idle": "2020-10-31T01:46:34.839804Z",
     "shell.execute_reply": "2020-10-31T01:46:34.838895Z"
    },
    "papermill": {
     "duration": 24.459122,
     "end_time": "2020-10-31T01:46:34.839941",
     "exception": false,
     "start_time": "2020-10-31T01:46:10.380819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn_train = fe_simple(train, remove_features)\n",
    "fn_test = fe_simple(test, remove_features)\n",
    "\n",
    "# xgb --------------------------\n",
    "#X = fe_xgb(fn_train)\n",
    "#X_test = fe_xgb(fn_test)\n",
    "\n",
    "# pytorch mlp -----------------------------------\n",
    "mlp_train, mlp_test = fe_mlp(train, test)\n",
    "mlp_train = fe_mlp2(mlp_train).to_numpy()\n",
    "mlp_test = fe_mlp2(mlp_test).to_numpy()\n",
    "\n",
    "# pytorch tabnet ----------------------------------\n",
    "tab_train = fn_train.copy()\n",
    "tab_test = fn_test.copy()\n",
    "\n",
    "ss = preprocessing.RobustScaler()\n",
    "tab_train= ss.fit_transform(tab_train)\n",
    "tab_test = ss.transform(tab_test)\n",
    "\n",
    "# pytorch lstm -------------------------------\n",
    "lstm_train = fe_lstm(train)\n",
    "lstm_test = fe_lstm(test)\n",
    "ss = preprocessing.RobustScaler()\n",
    "lstm_train= ss.fit_transform(lstm_train)\n",
    "lstm_test = ss.transform(lstm_test)\n",
    "\n",
    "# svm-----------------------\n",
    "ss = preprocessing.StandardScaler()\n",
    "fn_train= ss.fit_transform(fn_train)\n",
    "fn_test = ss.transform(fn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02923,
     "end_time": "2020-10-31T01:46:34.899747",
     "exception": false,
     "start_time": "2020-10-31T01:46:34.870517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:34.963841Z",
     "iopub.status.busy": "2020-10-31T01:46:34.963071Z",
     "iopub.status.idle": "2020-10-31T01:46:34.967246Z",
     "shell.execute_reply": "2020-10-31T01:46:34.967789Z"
    },
    "papermill": {
     "duration": 0.038409,
     "end_time": "2020-10-31T01:46:34.967929",
     "exception": false,
     "start_time": "2020-10-31T01:46:34.929520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.random.seed(42)\n",
    "#NFOLDS=5\n",
    "\n",
    "#classifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n",
    "\n",
    "#clf = Pipeline([('classify', classifier)\n",
    "#               ])\n",
    "\n",
    "#params = {'classify__estimator__gamma': 3.6975,\n",
    "#          'classify__estimator__learning_rate': 0.0803,\n",
    "#          'classify__estimator__max_delta_step': 2.0706,\n",
    "#          'classify__estimator__max_depth': 10,\n",
    "#          'classify__estimator__min_child_weight': 31.5800,\n",
    "#          'classify__estimator__n_estimators': 166,\n",
    "#         }\n",
    "\n",
    "#clf.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:35.031621Z",
     "iopub.status.busy": "2020-10-31T01:46:35.030957Z",
     "iopub.status.idle": "2020-10-31T01:46:35.035672Z",
     "shell.execute_reply": "2020-10-31T01:46:35.035115Z"
    },
    "papermill": {
     "duration": 0.038163,
     "end_time": "2020-10-31T01:46:35.035944",
     "exception": false,
     "start_time": "2020-10-31T01:46:34.997781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#xgb1_oof = np.zeros((X.shape[0], y.shape[1]))\n",
    "#xgb1_test = np.zeros((X_test.shape[0], y.shape[1]))\n",
    "#mskf = MultilabelStratifiedKFold(n_splits=NFOLDS, random_state=42, shuffle=True)\n",
    "#for fn, (trn_idx, val_idx) in enumerate(mskf.split(X, fn_targets)):\n",
    "#    X_train, X_val = X.iloc[trn_idx,:].to_numpy(), X.iloc[val_idx,:].to_numpy()\n",
    "#    y_train, y_val = fn_targets[trn_idx], fn_targets[val_idx]\n",
    "#    \n",
    "#    clf.fit(X_train, y_train)\n",
    "        \n",
    "#    val_preds = clf.predict_proba(X_val) # list of preds per class\n",
    "#    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n",
    "#    xgb1_oof[val_idx] = val_preds\n",
    "#    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n",
    "#    print(loss)\n",
    "        \n",
    "#    preds = clf.predict_proba(X_test)\n",
    "#    preds = np.array(preds)[:,:,1].T # take the positive class\n",
    "#    xgb1_test += preds / NFOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:35.100566Z",
     "iopub.status.busy": "2020-10-31T01:46:35.099593Z",
     "iopub.status.idle": "2020-10-31T01:46:35.102718Z",
     "shell.execute_reply": "2020-10-31T01:46:35.102163Z"
    },
    "papermill": {
     "duration": 0.036901,
     "end_time": "2020-10-31T01:46:35.102837",
     "exception": false,
     "start_time": "2020-10-31T01:46:35.065936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check_xgb = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "#check_xgb[cons_train_index,:] =  xgb1_oof\n",
    "#print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_xgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029976,
     "end_time": "2020-10-31T01:46:35.162978",
     "exception": false,
     "start_time": "2020-10-31T01:46:35.133002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:35.235547Z",
     "iopub.status.busy": "2020-10-31T01:46:35.234576Z",
     "iopub.status.idle": "2020-10-31T01:46:35.237164Z",
     "shell.execute_reply": "2020-10-31T01:46:35.237850Z"
    },
    "papermill": {
     "duration": 0.045,
     "end_time": "2020-10-31T01:46:35.237984",
     "exception": false,
     "start_time": "2020-10-31T01:46:35.192984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(device) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:35.302014Z",
     "iopub.status.busy": "2020-10-31T01:46:35.300869Z",
     "iopub.status.idle": "2020-10-31T01:46:35.364006Z",
     "shell.execute_reply": "2020-10-31T01:46:35.364515Z"
    },
    "papermill": {
     "duration": 0.097182,
     "end_time": "2020-10-31T01:46:35.364649",
     "exception": false,
     "start_time": "2020-10-31T01:46:35.267467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128\n",
    "n_folds=7\n",
    "train_epochs = 20\n",
    "smoothing = 0.001\n",
    "p_min = smoothing\n",
    "p_max = 1 - smoothing\n",
    "\n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(target_feats):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns, last_num):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 1024))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(1024, 1024))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, last_num))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu1(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu2(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def modelling_torch(X_train, y_train, X_test, sample_seed, last_num):\n",
    "    seed_everything(seed=sample_seed) \n",
    "\n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=224)\n",
    "    metric = lambda inputs, targets : F.binary_cross_entropy((torch.clamp(torch.sigmoid(inputs), p_min, p_max)), targets)\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    X_test2 = torch.tensor(X_test, dtype=torch.float32)\n",
    "    test = torch.utils.data.TensorDataset(X_test2) \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2 = torch.tensor(X_train[train_index,:], dtype=torch.float32)\n",
    "        X_valid2 = torch.tensor(X_train[valid_index,:], dtype=torch.float32)\n",
    "\n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2, y_valid2)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "        clf = MoaModel(mlp_train.shape[1], last_num)\n",
    "        loss_fn = SmoothCrossEntropyLoss(smoothing=smoothing)\n",
    "        \n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.001, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=train_epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        \n",
    "        for epoch in range(train_epochs):\n",
    "            clf.train()\n",
    "            sm_avg_loss = 0.\n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                sm_avg_loss += metric(y_pred, y_batch) / len(train_loader) \n",
    "                \n",
    "            clf.eval()\n",
    "            sm_avg_val_loss = 0.\n",
    "            \n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch).detach()\n",
    "                sm_avg_val_loss += metric(y_pred, y_batch) / len(valid_loader)\n",
    "                            \n",
    "            if sm_avg_val_loss < best_val_loss:\n",
    "                best_val_loss = sm_avg_val_loss\n",
    "                print('Epoch {} sm_loss={:.5f}  sm_val_loss={:.5f}'.format(epoch + 1, sm_avg_loss, sm_avg_val_loss))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "                \n",
    "        pred_model = MoaModel(mlp_train.shape[1], last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))         \n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            oof_epoch[i * batch_size:(i+1) * batch_size,:] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "            target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch,) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch).detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = torch.clamp(torch.sigmoid(y_pred.cpu()), p_min, p_max)\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "    \n",
    "    return oof, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T01:46:35.433649Z",
     "iopub.status.busy": "2020-10-31T01:46:35.432821Z",
     "iopub.status.idle": "2020-10-31T02:00:01.851860Z",
     "shell.execute_reply": "2020-10-31T02:00:01.851139Z"
    },
    "papermill": {
     "duration": 806.457026,
     "end_time": "2020-10-31T02:00:01.851989",
     "exception": false,
     "start_time": "2020-10-31T01:46:35.394963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41417  sm_val_loss=0.02222\n",
      "Epoch 2 sm_loss=0.02011  sm_val_loss=0.01953\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01902\n",
      "Epoch 4 sm_loss=0.01763  sm_val_loss=0.01781\n",
      "Epoch 5 sm_loss=0.01750  sm_val_loss=0.01770\n",
      "Epoch 6 sm_loss=0.01744  sm_val_loss=0.01759\n",
      "Epoch 7 sm_loss=0.01743  sm_val_loss=0.01740\n",
      "Epoch 8 sm_loss=0.01734  sm_val_loss=0.01735\n",
      "Epoch 11 sm_loss=0.01707  sm_val_loss=0.01709\n",
      "Epoch 12 sm_loss=0.01687  sm_val_loss=0.01680\n",
      "Epoch 13 sm_loss=0.01671  sm_val_loss=0.01674\n",
      "Epoch 14 sm_loss=0.01642  sm_val_loss=0.01673\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01636\n",
      "Epoch 16 sm_loss=0.01566  sm_val_loss=0.01632\n",
      "Epoch 17 sm_loss=0.01520  sm_val_loss=0.01608\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01598\n",
      "Epoch 19 sm_loss=0.01437  sm_val_loss=0.01595\n",
      "Epoch 20 sm_loss=0.01419  sm_val_loss=0.01592\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41399  sm_val_loss=0.02262\n",
      "Epoch 2 sm_loss=0.02004  sm_val_loss=0.02017\n",
      "Epoch 4 sm_loss=0.01781  sm_val_loss=0.01759\n",
      "Epoch 7 sm_loss=0.01742  sm_val_loss=0.01745\n",
      "Epoch 8 sm_loss=0.01737  sm_val_loss=0.01740\n",
      "Epoch 11 sm_loss=0.01709  sm_val_loss=0.01712\n",
      "Epoch 12 sm_loss=0.01686  sm_val_loss=0.01711\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01691\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01647\n",
      "Epoch 16 sm_loss=0.01561  sm_val_loss=0.01637\n",
      "Epoch 17 sm_loss=0.01516  sm_val_loss=0.01629\n",
      "Epoch 18 sm_loss=0.01472  sm_val_loss=0.01620\n",
      "Epoch 19 sm_loss=0.01431  sm_val_loss=0.01614\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41327  sm_val_loss=0.02234\n",
      "Epoch 2 sm_loss=0.02013  sm_val_loss=0.01860\n",
      "Epoch 3 sm_loss=0.01823  sm_val_loss=0.01806\n",
      "Epoch 4 sm_loss=0.01771  sm_val_loss=0.01723\n",
      "Epoch 6 sm_loss=0.01746  sm_val_loss=0.01707\n",
      "Epoch 10 sm_loss=0.01719  sm_val_loss=0.01691\n",
      "Epoch 11 sm_loss=0.01709  sm_val_loss=0.01670\n",
      "Epoch 13 sm_loss=0.01670  sm_val_loss=0.01643\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01634\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01615\n",
      "Epoch 16 sm_loss=0.01569  sm_val_loss=0.01598\n",
      "Epoch 17 sm_loss=0.01523  sm_val_loss=0.01591\n",
      "Epoch 18 sm_loss=0.01474  sm_val_loss=0.01582\n",
      "Epoch 19 sm_loss=0.01433  sm_val_loss=0.01572\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41474  sm_val_loss=0.02265\n",
      "Epoch 2 sm_loss=0.02026  sm_val_loss=0.01899\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01783\n",
      "Epoch 4 sm_loss=0.01763  sm_val_loss=0.01759\n",
      "Epoch 5 sm_loss=0.01744  sm_val_loss=0.01758\n",
      "Epoch 9 sm_loss=0.01728  sm_val_loss=0.01755\n",
      "Epoch 10 sm_loss=0.01717  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01680  sm_val_loss=0.01702\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01690\n",
      "Epoch 14 sm_loss=0.01628  sm_val_loss=0.01663\n",
      "Epoch 15 sm_loss=0.01605  sm_val_loss=0.01659\n",
      "Epoch 16 sm_loss=0.01558  sm_val_loss=0.01639\n",
      "Epoch 17 sm_loss=0.01509  sm_val_loss=0.01626\n",
      "Epoch 18 sm_loss=0.01463  sm_val_loss=0.01617\n",
      "Epoch 19 sm_loss=0.01422  sm_val_loss=0.01613\n",
      "Epoch 20 sm_loss=0.01398  sm_val_loss=0.01613\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41454  sm_val_loss=0.02291\n",
      "Epoch 2 sm_loss=0.02000  sm_val_loss=0.01854\n",
      "Epoch 3 sm_loss=0.01808  sm_val_loss=0.01815\n",
      "Epoch 4 sm_loss=0.01752  sm_val_loss=0.01771\n",
      "Epoch 8 sm_loss=0.01733  sm_val_loss=0.01769\n",
      "Epoch 9 sm_loss=0.01725  sm_val_loss=0.01764\n",
      "Epoch 10 sm_loss=0.01713  sm_val_loss=0.01755\n",
      "Epoch 11 sm_loss=0.01701  sm_val_loss=0.01733\n",
      "Epoch 13 sm_loss=0.01662  sm_val_loss=0.01710\n",
      "Epoch 14 sm_loss=0.01634  sm_val_loss=0.01686\n",
      "Epoch 15 sm_loss=0.01601  sm_val_loss=0.01664\n",
      "Epoch 16 sm_loss=0.01555  sm_val_loss=0.01654\n",
      "Epoch 17 sm_loss=0.01508  sm_val_loss=0.01645\n",
      "Epoch 18 sm_loss=0.01458  sm_val_loss=0.01637\n",
      "Epoch 19 sm_loss=0.01420  sm_val_loss=0.01631\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41390  sm_val_loss=0.02243\n",
      "Epoch 2 sm_loss=0.02009  sm_val_loss=0.01890\n",
      "Epoch 3 sm_loss=0.01825  sm_val_loss=0.01855\n",
      "Epoch 4 sm_loss=0.01764  sm_val_loss=0.01738\n",
      "Epoch 7 sm_loss=0.01742  sm_val_loss=0.01735\n",
      "Epoch 8 sm_loss=0.01740  sm_val_loss=0.01724\n",
      "Epoch 9 sm_loss=0.01738  sm_val_loss=0.01722\n",
      "Epoch 10 sm_loss=0.01727  sm_val_loss=0.01702\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01682\n",
      "Epoch 13 sm_loss=0.01675  sm_val_loss=0.01660\n",
      "Epoch 14 sm_loss=0.01646  sm_val_loss=0.01650\n",
      "Epoch 15 sm_loss=0.01611  sm_val_loss=0.01624\n",
      "Epoch 16 sm_loss=0.01578  sm_val_loss=0.01608\n",
      "Epoch 17 sm_loss=0.01530  sm_val_loss=0.01591\n",
      "Epoch 18 sm_loss=0.01483  sm_val_loss=0.01581\n",
      "Epoch 19 sm_loss=0.01448  sm_val_loss=0.01576\n",
      "Epoch 20 sm_loss=0.01428  sm_val_loss=0.01576\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41471  sm_val_loss=0.02247\n",
      "Epoch 2 sm_loss=0.02007  sm_val_loss=0.01854\n",
      "Epoch 3 sm_loss=0.01824  sm_val_loss=0.01780\n",
      "Epoch 4 sm_loss=0.01768  sm_val_loss=0.01753\n",
      "Epoch 5 sm_loss=0.01747  sm_val_loss=0.01750\n",
      "Epoch 8 sm_loss=0.01741  sm_val_loss=0.01728\n",
      "Epoch 10 sm_loss=0.01725  sm_val_loss=0.01708\n",
      "Epoch 11 sm_loss=0.01708  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01691  sm_val_loss=0.01689\n",
      "Epoch 13 sm_loss=0.01674  sm_val_loss=0.01682\n",
      "Epoch 14 sm_loss=0.01638  sm_val_loss=0.01651\n",
      "Epoch 15 sm_loss=0.01601  sm_val_loss=0.01632\n",
      "Epoch 16 sm_loss=0.01571  sm_val_loss=0.01622\n",
      "Epoch 17 sm_loss=0.01519  sm_val_loss=0.01611\n",
      "Epoch 18 sm_loss=0.01469  sm_val_loss=0.01602\n",
      "Epoch 19 sm_loss=0.01431  sm_val_loss=0.01597\n",
      "Epoch 20 sm_loss=0.01409  sm_val_loss=0.01596\n",
      "Seed 0\n",
      "Total log loss: 0.016019747647044533\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41406  sm_val_loss=0.02259\n",
      "Epoch 2 sm_loss=0.02008  sm_val_loss=0.01875\n",
      "Epoch 3 sm_loss=0.01814  sm_val_loss=0.01821\n",
      "Epoch 4 sm_loss=0.01764  sm_val_loss=0.01760\n",
      "Epoch 5 sm_loss=0.01741  sm_val_loss=0.01749\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01733\n",
      "Epoch 10 sm_loss=0.01723  sm_val_loss=0.01732\n",
      "Epoch 11 sm_loss=0.01704  sm_val_loss=0.01726\n",
      "Epoch 12 sm_loss=0.01695  sm_val_loss=0.01699\n",
      "Epoch 13 sm_loss=0.01667  sm_val_loss=0.01669\n",
      "Epoch 15 sm_loss=0.01604  sm_val_loss=0.01644\n",
      "Epoch 16 sm_loss=0.01573  sm_val_loss=0.01623\n",
      "Epoch 17 sm_loss=0.01526  sm_val_loss=0.01612\n",
      "Epoch 18 sm_loss=0.01478  sm_val_loss=0.01604\n",
      "Epoch 19 sm_loss=0.01440  sm_val_loss=0.01595\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41428  sm_val_loss=0.02257\n",
      "Epoch 2 sm_loss=0.02041  sm_val_loss=0.01965\n",
      "Epoch 3 sm_loss=0.01836  sm_val_loss=0.01791\n",
      "Epoch 5 sm_loss=0.01759  sm_val_loss=0.01762\n",
      "Epoch 6 sm_loss=0.01751  sm_val_loss=0.01755\n",
      "Epoch 9 sm_loss=0.01735  sm_val_loss=0.01721\n",
      "Epoch 12 sm_loss=0.01688  sm_val_loss=0.01697\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01671\n",
      "Epoch 15 sm_loss=0.01604  sm_val_loss=0.01651\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01632\n",
      "Epoch 17 sm_loss=0.01516  sm_val_loss=0.01629\n",
      "Epoch 18 sm_loss=0.01471  sm_val_loss=0.01613\n",
      "Epoch 19 sm_loss=0.01429  sm_val_loss=0.01610\n",
      "Epoch 20 sm_loss=0.01407  sm_val_loss=0.01608\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41425  sm_val_loss=0.02221\n",
      "Epoch 2 sm_loss=0.02001  sm_val_loss=0.01817\n",
      "Epoch 3 sm_loss=0.01825  sm_val_loss=0.01739\n",
      "Epoch 4 sm_loss=0.01763  sm_val_loss=0.01736\n",
      "Epoch 6 sm_loss=0.01754  sm_val_loss=0.01725\n",
      "Epoch 8 sm_loss=0.01742  sm_val_loss=0.01714\n",
      "Epoch 9 sm_loss=0.01735  sm_val_loss=0.01711\n",
      "Epoch 10 sm_loss=0.01724  sm_val_loss=0.01706\n",
      "Epoch 11 sm_loss=0.01718  sm_val_loss=0.01695\n",
      "Epoch 12 sm_loss=0.01690  sm_val_loss=0.01663\n",
      "Epoch 13 sm_loss=0.01673  sm_val_loss=0.01641\n",
      "Epoch 14 sm_loss=0.01644  sm_val_loss=0.01628\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01617\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01604\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01585\n",
      "Epoch 18 sm_loss=0.01473  sm_val_loss=0.01582\n",
      "Epoch 19 sm_loss=0.01434  sm_val_loss=0.01578\n",
      "Epoch 20 sm_loss=0.01411  sm_val_loss=0.01574\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41363  sm_val_loss=0.02255\n",
      "Epoch 2 sm_loss=0.02003  sm_val_loss=0.01884\n",
      "Epoch 3 sm_loss=0.01806  sm_val_loss=0.01802\n",
      "Epoch 4 sm_loss=0.01760  sm_val_loss=0.01797\n",
      "Epoch 5 sm_loss=0.01740  sm_val_loss=0.01777\n",
      "Epoch 6 sm_loss=0.01737  sm_val_loss=0.01750\n",
      "Epoch 8 sm_loss=0.01738  sm_val_loss=0.01711\n",
      "Epoch 13 sm_loss=0.01659  sm_val_loss=0.01687\n",
      "Epoch 14 sm_loss=0.01637  sm_val_loss=0.01667\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01661\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01643\n",
      "Epoch 17 sm_loss=0.01519  sm_val_loss=0.01633\n",
      "Epoch 18 sm_loss=0.01472  sm_val_loss=0.01618\n",
      "Epoch 19 sm_loss=0.01432  sm_val_loss=0.01612\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41480  sm_val_loss=0.02265\n",
      "Epoch 2 sm_loss=0.02000  sm_val_loss=0.01896\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01833\n",
      "Epoch 4 sm_loss=0.01755  sm_val_loss=0.01783\n",
      "Epoch 5 sm_loss=0.01743  sm_val_loss=0.01764\n",
      "Epoch 11 sm_loss=0.01708  sm_val_loss=0.01749\n",
      "Epoch 12 sm_loss=0.01685  sm_val_loss=0.01723\n",
      "Epoch 13 sm_loss=0.01662  sm_val_loss=0.01709\n",
      "Epoch 14 sm_loss=0.01637  sm_val_loss=0.01682\n",
      "Epoch 15 sm_loss=0.01602  sm_val_loss=0.01678\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01660\n",
      "Epoch 17 sm_loss=0.01522  sm_val_loss=0.01645\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01634\n",
      "Epoch 19 sm_loss=0.01439  sm_val_loss=0.01631\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41438  sm_val_loss=0.02245\n",
      "Epoch 2 sm_loss=0.02007  sm_val_loss=0.01876\n",
      "Epoch 3 sm_loss=0.01855  sm_val_loss=0.01770\n",
      "Epoch 4 sm_loss=0.01766  sm_val_loss=0.01750\n",
      "Epoch 6 sm_loss=0.01756  sm_val_loss=0.01739\n",
      "Epoch 7 sm_loss=0.01752  sm_val_loss=0.01730\n",
      "Epoch 9 sm_loss=0.01734  sm_val_loss=0.01716\n",
      "Epoch 10 sm_loss=0.01723  sm_val_loss=0.01714\n",
      "Epoch 11 sm_loss=0.01714  sm_val_loss=0.01688\n",
      "Epoch 12 sm_loss=0.01693  sm_val_loss=0.01683\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01669\n",
      "Epoch 14 sm_loss=0.01650  sm_val_loss=0.01649\n",
      "Epoch 15 sm_loss=0.01611  sm_val_loss=0.01637\n",
      "Epoch 16 sm_loss=0.01579  sm_val_loss=0.01617\n",
      "Epoch 17 sm_loss=0.01533  sm_val_loss=0.01599\n",
      "Epoch 18 sm_loss=0.01487  sm_val_loss=0.01588\n",
      "Epoch 19 sm_loss=0.01450  sm_val_loss=0.01580\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41382  sm_val_loss=0.02258\n",
      "Epoch 2 sm_loss=0.02019  sm_val_loss=0.01870\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01759\n",
      "Epoch 4 sm_loss=0.01759  sm_val_loss=0.01755\n",
      "Epoch 6 sm_loss=0.01750  sm_val_loss=0.01739\n",
      "Epoch 7 sm_loss=0.01743  sm_val_loss=0.01738\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01734\n",
      "Epoch 11 sm_loss=0.01712  sm_val_loss=0.01724\n",
      "Epoch 12 sm_loss=0.01690  sm_val_loss=0.01695\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01667\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01658\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01638\n",
      "Epoch 16 sm_loss=0.01566  sm_val_loss=0.01633\n",
      "Epoch 17 sm_loss=0.01523  sm_val_loss=0.01609\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01603\n",
      "Epoch 19 sm_loss=0.01437  sm_val_loss=0.01600\n",
      "Seed 1\n",
      "Total log loss: 0.01602759954171412\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41478  sm_val_loss=0.02309\n",
      "Epoch 2 sm_loss=0.02020  sm_val_loss=0.01892\n",
      "Epoch 3 sm_loss=0.01807  sm_val_loss=0.01786\n",
      "Epoch 5 sm_loss=0.01740  sm_val_loss=0.01766\n",
      "Epoch 6 sm_loss=0.01742  sm_val_loss=0.01750\n",
      "Epoch 8 sm_loss=0.01731  sm_val_loss=0.01745\n",
      "Epoch 9 sm_loss=0.01726  sm_val_loss=0.01733\n",
      "Epoch 12 sm_loss=0.01688  sm_val_loss=0.01695\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01682\n",
      "Epoch 14 sm_loss=0.01634  sm_val_loss=0.01664\n",
      "Epoch 15 sm_loss=0.01603  sm_val_loss=0.01645\n",
      "Epoch 16 sm_loss=0.01557  sm_val_loss=0.01626\n",
      "Epoch 17 sm_loss=0.01515  sm_val_loss=0.01611\n",
      "Epoch 18 sm_loss=0.01467  sm_val_loss=0.01602\n",
      "Epoch 19 sm_loss=0.01422  sm_val_loss=0.01595\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41456  sm_val_loss=0.02264\n",
      "Epoch 2 sm_loss=0.02006  sm_val_loss=0.01966\n",
      "Epoch 3 sm_loss=0.01812  sm_val_loss=0.01795\n",
      "Epoch 4 sm_loss=0.01755  sm_val_loss=0.01789\n",
      "Epoch 5 sm_loss=0.01748  sm_val_loss=0.01773\n",
      "Epoch 8 sm_loss=0.01744  sm_val_loss=0.01752\n",
      "Epoch 10 sm_loss=0.01722  sm_val_loss=0.01721\n",
      "Epoch 11 sm_loss=0.01709  sm_val_loss=0.01717\n",
      "Epoch 13 sm_loss=0.01664  sm_val_loss=0.01696\n",
      "Epoch 14 sm_loss=0.01640  sm_val_loss=0.01661\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01654\n",
      "Epoch 16 sm_loss=0.01571  sm_val_loss=0.01640\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01628\n",
      "Epoch 18 sm_loss=0.01476  sm_val_loss=0.01622\n",
      "Epoch 19 sm_loss=0.01438  sm_val_loss=0.01614\n",
      "Epoch 20 sm_loss=0.01419  sm_val_loss=0.01612\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41348  sm_val_loss=0.02245\n",
      "Epoch 2 sm_loss=0.02000  sm_val_loss=0.01825\n",
      "Epoch 3 sm_loss=0.01824  sm_val_loss=0.01755\n",
      "Epoch 4 sm_loss=0.01770  sm_val_loss=0.01739\n",
      "Epoch 5 sm_loss=0.01754  sm_val_loss=0.01733\n",
      "Epoch 6 sm_loss=0.01757  sm_val_loss=0.01721\n",
      "Epoch 7 sm_loss=0.01752  sm_val_loss=0.01719\n",
      "Epoch 8 sm_loss=0.01750  sm_val_loss=0.01714\n",
      "Epoch 9 sm_loss=0.01738  sm_val_loss=0.01703\n",
      "Epoch 10 sm_loss=0.01729  sm_val_loss=0.01693\n",
      "Epoch 11 sm_loss=0.01716  sm_val_loss=0.01681\n",
      "Epoch 12 sm_loss=0.01698  sm_val_loss=0.01657\n",
      "Epoch 14 sm_loss=0.01652  sm_val_loss=0.01634\n",
      "Epoch 15 sm_loss=0.01619  sm_val_loss=0.01623\n",
      "Epoch 16 sm_loss=0.01580  sm_val_loss=0.01601\n",
      "Epoch 17 sm_loss=0.01536  sm_val_loss=0.01586\n",
      "Epoch 18 sm_loss=0.01496  sm_val_loss=0.01575\n",
      "Epoch 19 sm_loss=0.01460  sm_val_loss=0.01574\n",
      "Epoch 20 sm_loss=0.01441  sm_val_loss=0.01573\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41455  sm_val_loss=0.02231\n",
      "Epoch 2 sm_loss=0.02003  sm_val_loss=0.01863\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01835\n",
      "Epoch 4 sm_loss=0.01752  sm_val_loss=0.01828\n",
      "Epoch 5 sm_loss=0.01745  sm_val_loss=0.01768\n",
      "Epoch 6 sm_loss=0.01744  sm_val_loss=0.01749\n",
      "Epoch 8 sm_loss=0.01740  sm_val_loss=0.01738\n",
      "Epoch 10 sm_loss=0.01718  sm_val_loss=0.01732\n",
      "Epoch 11 sm_loss=0.01701  sm_val_loss=0.01725\n",
      "Epoch 12 sm_loss=0.01681  sm_val_loss=0.01707\n",
      "Epoch 13 sm_loss=0.01664  sm_val_loss=0.01704\n",
      "Epoch 14 sm_loss=0.01633  sm_val_loss=0.01674\n",
      "Epoch 15 sm_loss=0.01600  sm_val_loss=0.01657\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01652\n",
      "Epoch 17 sm_loss=0.01516  sm_val_loss=0.01632\n",
      "Epoch 18 sm_loss=0.01470  sm_val_loss=0.01621\n",
      "Epoch 19 sm_loss=0.01432  sm_val_loss=0.01617\n",
      "Epoch 20 sm_loss=0.01414  sm_val_loss=0.01614\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41370  sm_val_loss=0.02295\n",
      "Epoch 2 sm_loss=0.02015  sm_val_loss=0.02016\n",
      "Epoch 3 sm_loss=0.01823  sm_val_loss=0.01784\n",
      "Epoch 5 sm_loss=0.01744  sm_val_loss=0.01762\n",
      "Epoch 9 sm_loss=0.01721  sm_val_loss=0.01756\n",
      "Epoch 10 sm_loss=0.01717  sm_val_loss=0.01743\n",
      "Epoch 11 sm_loss=0.01705  sm_val_loss=0.01725\n",
      "Epoch 12 sm_loss=0.01679  sm_val_loss=0.01721\n",
      "Epoch 13 sm_loss=0.01662  sm_val_loss=0.01699\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01667\n",
      "Epoch 16 sm_loss=0.01565  sm_val_loss=0.01656\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01639\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01639\n",
      "Epoch 19 sm_loss=0.01440  sm_val_loss=0.01630\n",
      "Epoch 20 sm_loss=0.01418  sm_val_loss=0.01630\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41409  sm_val_loss=0.02212\n",
      "Epoch 2 sm_loss=0.02030  sm_val_loss=0.01864\n",
      "Epoch 3 sm_loss=0.01817  sm_val_loss=0.01765\n",
      "Epoch 4 sm_loss=0.01761  sm_val_loss=0.01746\n",
      "Epoch 7 sm_loss=0.01745  sm_val_loss=0.01741\n",
      "Epoch 9 sm_loss=0.01743  sm_val_loss=0.01735\n",
      "Epoch 10 sm_loss=0.01731  sm_val_loss=0.01710\n",
      "Epoch 12 sm_loss=0.01697  sm_val_loss=0.01684\n",
      "Epoch 13 sm_loss=0.01676  sm_val_loss=0.01654\n",
      "Epoch 14 sm_loss=0.01645  sm_val_loss=0.01645\n",
      "Epoch 15 sm_loss=0.01622  sm_val_loss=0.01628\n",
      "Epoch 16 sm_loss=0.01578  sm_val_loss=0.01613\n",
      "Epoch 17 sm_loss=0.01540  sm_val_loss=0.01598\n",
      "Epoch 18 sm_loss=0.01492  sm_val_loss=0.01586\n",
      "Epoch 19 sm_loss=0.01454  sm_val_loss=0.01581\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41460  sm_val_loss=0.02264\n",
      "Epoch 2 sm_loss=0.02007  sm_val_loss=0.01872\n",
      "Epoch 3 sm_loss=0.01818  sm_val_loss=0.01775\n",
      "Epoch 4 sm_loss=0.01762  sm_val_loss=0.01770\n",
      "Epoch 5 sm_loss=0.01752  sm_val_loss=0.01741\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01740\n",
      "Epoch 9 sm_loss=0.01728  sm_val_loss=0.01726\n",
      "Epoch 10 sm_loss=0.01724  sm_val_loss=0.01724\n",
      "Epoch 11 sm_loss=0.01702  sm_val_loss=0.01697\n",
      "Epoch 12 sm_loss=0.01693  sm_val_loss=0.01693\n",
      "Epoch 13 sm_loss=0.01669  sm_val_loss=0.01669\n",
      "Epoch 14 sm_loss=0.01633  sm_val_loss=0.01654\n",
      "Epoch 15 sm_loss=0.01601  sm_val_loss=0.01645\n",
      "Epoch 16 sm_loss=0.01562  sm_val_loss=0.01623\n",
      "Epoch 17 sm_loss=0.01521  sm_val_loss=0.01616\n",
      "Epoch 18 sm_loss=0.01470  sm_val_loss=0.01603\n",
      "Epoch 19 sm_loss=0.01436  sm_val_loss=0.01597\n",
      "Epoch 20 sm_loss=0.01412  sm_val_loss=0.01596\n",
      "Seed 2\n",
      "Total log loss: 0.016031838518680914\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41534  sm_val_loss=0.02231\n",
      "Epoch 2 sm_loss=0.01989  sm_val_loss=0.01894\n",
      "Epoch 3 sm_loss=0.01799  sm_val_loss=0.01773\n",
      "Epoch 6 sm_loss=0.01745  sm_val_loss=0.01761\n",
      "Epoch 7 sm_loss=0.01747  sm_val_loss=0.01747\n",
      "Epoch 9 sm_loss=0.01736  sm_val_loss=0.01737\n",
      "Epoch 11 sm_loss=0.01708  sm_val_loss=0.01736\n",
      "Epoch 12 sm_loss=0.01689  sm_val_loss=0.01696\n",
      "Epoch 13 sm_loss=0.01669  sm_val_loss=0.01676\n",
      "Epoch 14 sm_loss=0.01645  sm_val_loss=0.01666\n",
      "Epoch 15 sm_loss=0.01608  sm_val_loss=0.01655\n",
      "Epoch 16 sm_loss=0.01572  sm_val_loss=0.01632\n",
      "Epoch 17 sm_loss=0.01524  sm_val_loss=0.01609\n",
      "Epoch 18 sm_loss=0.01480  sm_val_loss=0.01602\n",
      "Epoch 19 sm_loss=0.01443  sm_val_loss=0.01596\n",
      "Epoch 20 sm_loss=0.01422  sm_val_loss=0.01595\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41378  sm_val_loss=0.02261\n",
      "Epoch 2 sm_loss=0.02012  sm_val_loss=0.01925\n",
      "Epoch 3 sm_loss=0.01806  sm_val_loss=0.01794\n",
      "Epoch 4 sm_loss=0.01758  sm_val_loss=0.01769\n",
      "Epoch 5 sm_loss=0.01752  sm_val_loss=0.01764\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01743\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01723\n",
      "Epoch 12 sm_loss=0.01689  sm_val_loss=0.01703\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01699\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01675\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01668\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01636\n",
      "Epoch 17 sm_loss=0.01528  sm_val_loss=0.01630\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01619\n",
      "Epoch 19 sm_loss=0.01436  sm_val_loss=0.01617\n",
      "Epoch 20 sm_loss=0.01415  sm_val_loss=0.01616\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41496  sm_val_loss=0.02223\n",
      "Epoch 2 sm_loss=0.02010  sm_val_loss=0.02017\n",
      "Epoch 3 sm_loss=0.01825  sm_val_loss=0.01754\n",
      "Epoch 4 sm_loss=0.01756  sm_val_loss=0.01724\n",
      "Epoch 6 sm_loss=0.01747  sm_val_loss=0.01705\n",
      "Epoch 10 sm_loss=0.01720  sm_val_loss=0.01704\n",
      "Epoch 11 sm_loss=0.01711  sm_val_loss=0.01671\n",
      "Epoch 13 sm_loss=0.01665  sm_val_loss=0.01647\n",
      "Epoch 14 sm_loss=0.01649  sm_val_loss=0.01629\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01620\n",
      "Epoch 16 sm_loss=0.01570  sm_val_loss=0.01605\n",
      "Epoch 17 sm_loss=0.01525  sm_val_loss=0.01591\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01578\n",
      "Epoch 19 sm_loss=0.01440  sm_val_loss=0.01577\n",
      "Epoch 20 sm_loss=0.01419  sm_val_loss=0.01575\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41302  sm_val_loss=0.02299\n",
      "Epoch 2 sm_loss=0.02002  sm_val_loss=0.02096\n",
      "Epoch 3 sm_loss=0.01845  sm_val_loss=0.01824\n",
      "Epoch 4 sm_loss=0.01767  sm_val_loss=0.01764\n",
      "Epoch 6 sm_loss=0.01741  sm_val_loss=0.01759\n",
      "Epoch 8 sm_loss=0.01742  sm_val_loss=0.01747\n",
      "Epoch 9 sm_loss=0.01734  sm_val_loss=0.01740\n",
      "Epoch 10 sm_loss=0.01718  sm_val_loss=0.01733\n",
      "Epoch 11 sm_loss=0.01704  sm_val_loss=0.01721\n",
      "Epoch 12 sm_loss=0.01689  sm_val_loss=0.01716\n",
      "Epoch 13 sm_loss=0.01660  sm_val_loss=0.01678\n",
      "Epoch 15 sm_loss=0.01607  sm_val_loss=0.01666\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01648\n",
      "Epoch 17 sm_loss=0.01527  sm_val_loss=0.01623\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01618\n",
      "Epoch 19 sm_loss=0.01435  sm_val_loss=0.01615\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41413  sm_val_loss=0.02258\n",
      "Epoch 2 sm_loss=0.02008  sm_val_loss=0.01920\n",
      "Epoch 3 sm_loss=0.01822  sm_val_loss=0.01871\n",
      "Epoch 4 sm_loss=0.01749  sm_val_loss=0.01788\n",
      "Epoch 5 sm_loss=0.01749  sm_val_loss=0.01778\n",
      "Epoch 6 sm_loss=0.01743  sm_val_loss=0.01767\n",
      "Epoch 9 sm_loss=0.01730  sm_val_loss=0.01762\n",
      "Epoch 10 sm_loss=0.01716  sm_val_loss=0.01753\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01733\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01702\n",
      "Epoch 14 sm_loss=0.01636  sm_val_loss=0.01689\n",
      "Epoch 15 sm_loss=0.01600  sm_val_loss=0.01676\n",
      "Epoch 16 sm_loss=0.01563  sm_val_loss=0.01655\n",
      "Epoch 17 sm_loss=0.01520  sm_val_loss=0.01647\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01637\n",
      "Epoch 19 sm_loss=0.01438  sm_val_loss=0.01632\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41444  sm_val_loss=0.02202\n",
      "Epoch 2 sm_loss=0.02005  sm_val_loss=0.01875\n",
      "Epoch 3 sm_loss=0.01826  sm_val_loss=0.01735\n",
      "Epoch 9 sm_loss=0.01732  sm_val_loss=0.01705\n",
      "Epoch 11 sm_loss=0.01713  sm_val_loss=0.01700\n",
      "Epoch 12 sm_loss=0.01695  sm_val_loss=0.01697\n",
      "Epoch 13 sm_loss=0.01676  sm_val_loss=0.01656\n",
      "Epoch 15 sm_loss=0.01612  sm_val_loss=0.01636\n",
      "Epoch 16 sm_loss=0.01578  sm_val_loss=0.01609\n",
      "Epoch 17 sm_loss=0.01537  sm_val_loss=0.01595\n",
      "Epoch 18 sm_loss=0.01488  sm_val_loss=0.01586\n",
      "Epoch 19 sm_loss=0.01450  sm_val_loss=0.01581\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41483  sm_val_loss=0.02235\n",
      "Epoch 2 sm_loss=0.02015  sm_val_loss=0.01904\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01764\n",
      "Epoch 4 sm_loss=0.01755  sm_val_loss=0.01748\n",
      "Epoch 5 sm_loss=0.01748  sm_val_loss=0.01738\n",
      "Epoch 10 sm_loss=0.01715  sm_val_loss=0.01721\n",
      "Epoch 11 sm_loss=0.01707  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01690  sm_val_loss=0.01681\n",
      "Epoch 14 sm_loss=0.01640  sm_val_loss=0.01665\n",
      "Epoch 15 sm_loss=0.01610  sm_val_loss=0.01646\n",
      "Epoch 16 sm_loss=0.01568  sm_val_loss=0.01619\n",
      "Epoch 17 sm_loss=0.01524  sm_val_loss=0.01607\n",
      "Epoch 18 sm_loss=0.01477  sm_val_loss=0.01598\n",
      "Epoch 19 sm_loss=0.01441  sm_val_loss=0.01592\n",
      "Seed 3\n",
      "Total log loss: 0.016037907744538272\n",
      "Fold 1\n",
      "Epoch 1 sm_loss=0.41379  sm_val_loss=0.02282\n",
      "Epoch 2 sm_loss=0.02008  sm_val_loss=0.01954\n",
      "Epoch 3 sm_loss=0.01812  sm_val_loss=0.01798\n",
      "Epoch 4 sm_loss=0.01750  sm_val_loss=0.01761\n",
      "Epoch 5 sm_loss=0.01739  sm_val_loss=0.01747\n",
      "Epoch 10 sm_loss=0.01713  sm_val_loss=0.01707\n",
      "Epoch 12 sm_loss=0.01686  sm_val_loss=0.01704\n",
      "Epoch 13 sm_loss=0.01667  sm_val_loss=0.01674\n",
      "Epoch 14 sm_loss=0.01639  sm_val_loss=0.01661\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01645\n",
      "Epoch 16 sm_loss=0.01564  sm_val_loss=0.01626\n",
      "Epoch 17 sm_loss=0.01520  sm_val_loss=0.01611\n",
      "Epoch 18 sm_loss=0.01471  sm_val_loss=0.01598\n",
      "Epoch 19 sm_loss=0.01433  sm_val_loss=0.01597\n",
      "Fold 2\n",
      "Epoch 1 sm_loss=0.41524  sm_val_loss=0.02247\n",
      "Epoch 2 sm_loss=0.01994  sm_val_loss=0.01952\n",
      "Epoch 3 sm_loss=0.01807  sm_val_loss=0.01794\n",
      "Epoch 4 sm_loss=0.01757  sm_val_loss=0.01786\n",
      "Epoch 5 sm_loss=0.01748  sm_val_loss=0.01774\n",
      "Epoch 6 sm_loss=0.01745  sm_val_loss=0.01756\n",
      "Epoch 10 sm_loss=0.01724  sm_val_loss=0.01719\n",
      "Epoch 12 sm_loss=0.01688  sm_val_loss=0.01703\n",
      "Epoch 13 sm_loss=0.01670  sm_val_loss=0.01698\n",
      "Epoch 14 sm_loss=0.01639  sm_val_loss=0.01676\n",
      "Epoch 15 sm_loss=0.01604  sm_val_loss=0.01662\n",
      "Epoch 16 sm_loss=0.01569  sm_val_loss=0.01645\n",
      "Epoch 17 sm_loss=0.01522  sm_val_loss=0.01628\n",
      "Epoch 18 sm_loss=0.01475  sm_val_loss=0.01620\n",
      "Epoch 19 sm_loss=0.01434  sm_val_loss=0.01617\n",
      "Fold 3\n",
      "Epoch 1 sm_loss=0.41405  sm_val_loss=0.02261\n",
      "Epoch 2 sm_loss=0.02014  sm_val_loss=0.01858\n",
      "Epoch 3 sm_loss=0.01821  sm_val_loss=0.01788\n",
      "Epoch 4 sm_loss=0.01774  sm_val_loss=0.01737\n",
      "Epoch 6 sm_loss=0.01748  sm_val_loss=0.01731\n",
      "Epoch 8 sm_loss=0.01743  sm_val_loss=0.01707\n",
      "Epoch 9 sm_loss=0.01731  sm_val_loss=0.01704\n",
      "Epoch 10 sm_loss=0.01726  sm_val_loss=0.01676\n",
      "Epoch 11 sm_loss=0.01706  sm_val_loss=0.01672\n",
      "Epoch 12 sm_loss=0.01694  sm_val_loss=0.01671\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01649\n",
      "Epoch 14 sm_loss=0.01641  sm_val_loss=0.01637\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01616\n",
      "Epoch 16 sm_loss=0.01568  sm_val_loss=0.01601\n",
      "Epoch 17 sm_loss=0.01528  sm_val_loss=0.01580\n",
      "Epoch 18 sm_loss=0.01479  sm_val_loss=0.01579\n",
      "Epoch 19 sm_loss=0.01441  sm_val_loss=0.01570\n",
      "Fold 4\n",
      "Epoch 1 sm_loss=0.41399  sm_val_loss=0.02237\n",
      "Epoch 2 sm_loss=0.02001  sm_val_loss=0.01914\n",
      "Epoch 3 sm_loss=0.01812  sm_val_loss=0.01852\n",
      "Epoch 4 sm_loss=0.01770  sm_val_loss=0.01747\n",
      "Epoch 10 sm_loss=0.01717  sm_val_loss=0.01717\n",
      "Epoch 12 sm_loss=0.01685  sm_val_loss=0.01694\n",
      "Epoch 13 sm_loss=0.01661  sm_val_loss=0.01671\n",
      "Epoch 15 sm_loss=0.01602  sm_val_loss=0.01665\n",
      "Epoch 16 sm_loss=0.01563  sm_val_loss=0.01646\n",
      "Epoch 17 sm_loss=0.01513  sm_val_loss=0.01634\n",
      "Epoch 18 sm_loss=0.01468  sm_val_loss=0.01616\n",
      "Epoch 19 sm_loss=0.01430  sm_val_loss=0.01611\n",
      "Epoch 20 sm_loss=0.01408  sm_val_loss=0.01611\n",
      "Fold 5\n",
      "Epoch 1 sm_loss=0.41480  sm_val_loss=0.02310\n",
      "Epoch 2 sm_loss=0.02002  sm_val_loss=0.01839\n",
      "Epoch 3 sm_loss=0.01841  sm_val_loss=0.01785\n",
      "Epoch 6 sm_loss=0.01740  sm_val_loss=0.01752\n",
      "Epoch 8 sm_loss=0.01739  sm_val_loss=0.01747\n",
      "Epoch 10 sm_loss=0.01716  sm_val_loss=0.01744\n",
      "Epoch 11 sm_loss=0.01701  sm_val_loss=0.01735\n",
      "Epoch 12 sm_loss=0.01700  sm_val_loss=0.01729\n",
      "Epoch 13 sm_loss=0.01666  sm_val_loss=0.01721\n",
      "Epoch 14 sm_loss=0.01638  sm_val_loss=0.01695\n",
      "Epoch 15 sm_loss=0.01609  sm_val_loss=0.01676\n",
      "Epoch 16 sm_loss=0.01567  sm_val_loss=0.01666\n",
      "Epoch 17 sm_loss=0.01523  sm_val_loss=0.01648\n",
      "Epoch 18 sm_loss=0.01481  sm_val_loss=0.01640\n",
      "Epoch 19 sm_loss=0.01441  sm_val_loss=0.01636\n",
      "Epoch 20 sm_loss=0.01424  sm_val_loss=0.01630\n",
      "Fold 6\n",
      "Epoch 1 sm_loss=0.41412  sm_val_loss=0.02232\n",
      "Epoch 2 sm_loss=0.02019  sm_val_loss=0.01857\n",
      "Epoch 3 sm_loss=0.01807  sm_val_loss=0.01779\n",
      "Epoch 4 sm_loss=0.01771  sm_val_loss=0.01747\n",
      "Epoch 5 sm_loss=0.01759  sm_val_loss=0.01741\n",
      "Epoch 6 sm_loss=0.01751  sm_val_loss=0.01740\n",
      "Epoch 8 sm_loss=0.01746  sm_val_loss=0.01721\n",
      "Epoch 10 sm_loss=0.01726  sm_val_loss=0.01705\n",
      "Epoch 11 sm_loss=0.01712  sm_val_loss=0.01696\n",
      "Epoch 12 sm_loss=0.01699  sm_val_loss=0.01689\n",
      "Epoch 13 sm_loss=0.01677  sm_val_loss=0.01664\n",
      "Epoch 14 sm_loss=0.01648  sm_val_loss=0.01647\n",
      "Epoch 15 sm_loss=0.01613  sm_val_loss=0.01628\n",
      "Epoch 16 sm_loss=0.01573  sm_val_loss=0.01611\n",
      "Epoch 17 sm_loss=0.01529  sm_val_loss=0.01594\n",
      "Epoch 18 sm_loss=0.01483  sm_val_loss=0.01584\n",
      "Epoch 19 sm_loss=0.01445  sm_val_loss=0.01578\n",
      "Fold 7\n",
      "Epoch 1 sm_loss=0.41370  sm_val_loss=0.02277\n",
      "Epoch 2 sm_loss=0.02010  sm_val_loss=0.01848\n",
      "Epoch 3 sm_loss=0.01819  sm_val_loss=0.01783\n",
      "Epoch 4 sm_loss=0.01791  sm_val_loss=0.01782\n",
      "Epoch 5 sm_loss=0.01762  sm_val_loss=0.01743\n",
      "Epoch 7 sm_loss=0.01750  sm_val_loss=0.01734\n",
      "Epoch 9 sm_loss=0.01738  sm_val_loss=0.01729\n",
      "Epoch 10 sm_loss=0.01722  sm_val_loss=0.01726\n",
      "Epoch 11 sm_loss=0.01712  sm_val_loss=0.01711\n",
      "Epoch 12 sm_loss=0.01692  sm_val_loss=0.01699\n",
      "Epoch 13 sm_loss=0.01668  sm_val_loss=0.01686\n",
      "Epoch 14 sm_loss=0.01644  sm_val_loss=0.01654\n",
      "Epoch 15 sm_loss=0.01606  sm_val_loss=0.01637\n",
      "Epoch 16 sm_loss=0.01573  sm_val_loss=0.01625\n",
      "Epoch 17 sm_loss=0.01528  sm_val_loss=0.01608\n",
      "Epoch 18 sm_loss=0.01483  sm_val_loss=0.01596\n",
      "Epoch 19 sm_loss=0.01443  sm_val_loss=0.01592\n",
      "Seed 4\n",
      "Total log loss: 0.01601924208855057\n"
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4]\n",
    "mlp1_oof = np.zeros([len(mlp_train),fn_targets.shape[1]])\n",
    "mlp1_test = np.zeros([len(mlp_test),fn_targets.shape[1]])\n",
    "\n",
    "for seed_ in seeds:\n",
    "    oof, pytorch_pred = modelling_torch(mlp_train, fn_targets, mlp_test, seed_, fn_targets.shape[1])\n",
    "    mlp1_oof += oof / len(seeds)\n",
    "    mlp1_test += pytorch_pred / len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:00:02.384136Z",
     "iopub.status.busy": "2020-10-31T02:00:02.382423Z",
     "iopub.status.idle": "2020-10-31T02:00:03.906968Z",
     "shell.execute_reply": "2020-10-31T02:00:03.908355Z"
    },
    "papermill": {
     "duration": 1.798539,
     "end_time": "2020-10-31T02:00:03.908576",
     "exception": false,
     "start_time": "2020-10-31T02:00:02.110037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.014597014592739207\n"
     ]
    }
   ],
   "source": [
    "check_mlp = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "check_mlp[cons_train_index,:] = mlp1_oof\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.269805,
     "end_time": "2020-10-31T02:00:04.454126",
     "exception": false,
     "start_time": "2020-10-31T02:00:04.184321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:00:05.002148Z",
     "iopub.status.busy": "2020-10-31T02:00:05.000167Z",
     "iopub.status.idle": "2020-10-31T02:00:05.002892Z",
     "shell.execute_reply": "2020-10-31T02:00:05.003420Z"
    },
    "papermill": {
     "duration": 0.265846,
     "end_time": "2020-10-31T02:00:05.003567",
     "exception": false,
     "start_time": "2020-10-31T02:00:04.737721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1-y_true)*np.log(1-logits+1e-15) + y_true*np.log(logits+1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:00:05.606073Z",
     "iopub.status.busy": "2020-10-31T02:00:05.605085Z",
     "iopub.status.idle": "2020-10-31T02:00:05.608735Z",
     "shell.execute_reply": "2020-10-31T02:00:05.608181Z"
    },
    "papermill": {
     "duration": 0.346016,
     "end_time": "2020-10-31T02:00:05.608862",
     "exception": false,
     "start_time": "2020-10-31T02:00:05.262846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH=200\n",
    "\n",
    "def seed_tabnet_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "def modelling_tabnet(tr, target, te, sample_seed):\n",
    "    seed_tabnet_everything(sample_seed) \n",
    "    tabnet_params = dict(n_d=12, n_a=12, n_steps=1, gamma=1.3, seed = sample_seed,\n",
    "                     lambda_sparse=0, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type='entmax',\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=5,\n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.9,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=10,\n",
    "                     )\n",
    "    test_cv_preds = []\n",
    "    \n",
    "    NB_SPLITS = 5\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, random_state=0, shuffle=True)\n",
    "    oof_preds = np.zeros([len(tr),target.shape[1]])\n",
    "    for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train, target)):\n",
    "        print(\"FOLDS : \", fold_nb+1)\n",
    "\n",
    "        ## model\n",
    "        X_train, y_train = tr[train_idx, :], target[train_idx, :]\n",
    "        X_val, y_val = tr[val_idx, :], target[val_idx, :]\n",
    "        model = TabNetRegressor(**tabnet_params)\n",
    "        \n",
    "        model.fit(X_train=X_train,\n",
    "              y_train=y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_name = [\"val\"],\n",
    "              eval_metric = [\"logits_ll\"],\n",
    "              max_epochs=MAX_EPOCH,\n",
    "              patience=20, batch_size=1024, virtual_batch_size=128,\n",
    "              num_workers=1, drop_last=False,\n",
    "              # use binary cross entropy as this is not a regression problem\n",
    "              loss_fn=torch.nn.functional.binary_cross_entropy_with_logits)\n",
    "        \n",
    "        preds_val = model.predict(X_val)\n",
    "        preds =  1 / (1 + np.exp(-preds_val))\n",
    "        oof_preds[val_idx,:] = preds\n",
    "        \n",
    "        # preds on test\n",
    "        preds_test = model.predict(te)\n",
    "        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "    test_preds_all = np.stack(test_cv_preds)\n",
    "    return oof_preds, test_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:00:06.127895Z",
     "iopub.status.busy": "2020-10-31T02:00:06.126880Z",
     "iopub.status.idle": "2020-10-31T02:12:15.969429Z",
     "shell.execute_reply": "2020-10-31T02:12:15.968389Z"
    },
    "papermill": {
     "duration": 730.105368,
     "end_time": "2020-10-31T02:12:15.969582",
     "exception": false,
     "start_time": "2020-10-31T02:00:05.864214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDS :  1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56805 | val_logits_ll: 0.30547 |  0:00:01s\n",
      "epoch 10 | loss: 0.02066 | val_logits_ll: 0.02053 |  0:00:13s\n",
      "epoch 20 | loss: 0.01902 | val_logits_ll: 0.01885 |  0:00:24s\n",
      "epoch 30 | loss: 0.01782 | val_logits_ll: 0.01842 |  0:00:35s\n",
      "epoch 40 | loss: 0.01723 | val_logits_ll: 0.01774 |  0:00:48s\n",
      "epoch 50 | loss: 0.01699 | val_logits_ll: 0.01863 |  0:01:00s\n",
      "epoch 60 | loss: 0.01669 | val_logits_ll: 0.01722 |  0:01:12s\n",
      "epoch 70 | loss: 0.0167  | val_logits_ll: 0.0171  |  0:01:23s\n",
      "epoch 80 | loss: 0.01643 | val_logits_ll: 0.01703 |  0:01:35s\n",
      "epoch 90 | loss: 0.01611 | val_logits_ll: 0.01693 |  0:01:47s\n",
      "epoch 100| loss: 0.01599 | val_logits_ll: 0.01745 |  0:01:59s\n",
      "\n",
      "Early stopping occured at epoch 104 with best_epoch = 84 and best_val_logits_ll = 0.01675\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56657 | val_logits_ll: 0.30328 |  0:00:01s\n",
      "epoch 10 | loss: 0.02066 | val_logits_ll: 0.02041 |  0:00:12s\n",
      "epoch 20 | loss: 0.01867 | val_logits_ll: 0.0188  |  0:00:24s\n",
      "epoch 30 | loss: 0.01749 | val_logits_ll: 0.01904 |  0:00:35s\n",
      "epoch 40 | loss: 0.017   | val_logits_ll: 0.01937 |  0:00:48s\n",
      "epoch 50 | loss: 0.01662 | val_logits_ll: 0.01784 |  0:01:00s\n",
      "epoch 60 | loss: 0.01631 | val_logits_ll: 0.01738 |  0:01:11s\n",
      "epoch 70 | loss: 0.01606 | val_logits_ll: 0.01742 |  0:01:23s\n",
      "epoch 80 | loss: 0.0158  | val_logits_ll: 0.01729 |  0:01:34s\n",
      "epoch 90 | loss: 0.01559 | val_logits_ll: 0.01755 |  0:01:46s\n",
      "\n",
      "Early stopping occured at epoch 94 with best_epoch = 74 and best_val_logits_ll = 0.01715\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56895 | val_logits_ll: 0.29383 |  0:00:01s\n",
      "epoch 10 | loss: 0.02061 | val_logits_ll: 0.02049 |  0:00:12s\n",
      "epoch 20 | loss: 0.01867 | val_logits_ll: 0.01884 |  0:00:23s\n",
      "epoch 30 | loss: 0.01788 | val_logits_ll: 0.01938 |  0:00:35s\n",
      "epoch 40 | loss: 0.01737 | val_logits_ll: 0.01834 |  0:00:47s\n",
      "epoch 50 | loss: 0.01688 | val_logits_ll: 0.01768 |  0:00:59s\n",
      "epoch 60 | loss: 0.01663 | val_logits_ll: 0.01734 |  0:01:11s\n",
      "epoch 70 | loss: 0.01632 | val_logits_ll: 0.01753 |  0:01:22s\n",
      "epoch 80 | loss: 0.01608 | val_logits_ll: 0.01765 |  0:01:34s\n",
      "epoch 90 | loss: 0.01596 | val_logits_ll: 0.01717 |  0:01:46s\n",
      "epoch 100| loss: 0.01578 | val_logits_ll: 0.01717 |  0:01:59s\n",
      "epoch 110| loss: 0.01548 | val_logits_ll: 0.01752 |  0:02:11s\n",
      "epoch 120| loss: 0.0153  | val_logits_ll: 0.01721 |  0:02:22s\n",
      "\n",
      "Early stopping occured at epoch 122 with best_epoch = 102 and best_val_logits_ll = 0.01708\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56326 | val_logits_ll: 0.30779 |  0:00:01s\n",
      "epoch 10 | loss: 0.02077 | val_logits_ll: 0.02068 |  0:00:13s\n",
      "epoch 20 | loss: 0.01976 | val_logits_ll: 0.02129 |  0:00:26s\n",
      "epoch 30 | loss: 0.01805 | val_logits_ll: 0.01843 |  0:00:38s\n",
      "epoch 40 | loss: 0.01747 | val_logits_ll: 0.01914 |  0:00:51s\n",
      "epoch 50 | loss: 0.01699 | val_logits_ll: 0.01756 |  0:01:03s\n",
      "epoch 60 | loss: 0.01654 | val_logits_ll: 0.01726 |  0:01:15s\n",
      "epoch 70 | loss: 0.01631 | val_logits_ll: 0.01722 |  0:01:29s\n",
      "epoch 80 | loss: 0.01591 | val_logits_ll: 0.01715 |  0:01:41s\n",
      "epoch 90 | loss: 0.01603 | val_logits_ll: 0.01704 |  0:01:54s\n",
      "epoch 100| loss: 0.01577 | val_logits_ll: 0.01713 |  0:02:06s\n",
      "epoch 110| loss: 0.01563 | val_logits_ll: 0.01701 |  0:02:18s\n",
      "epoch 120| loss: 0.01537 | val_logits_ll: 0.01705 |  0:02:33s\n",
      "\n",
      "Early stopping occured at epoch 125 with best_epoch = 105 and best_val_logits_ll = 0.01688\n",
      "Best weights from best epoch are automatically used!\n",
      "FOLDS :  5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.56189 | val_logits_ll: 0.28975 |  0:00:01s\n",
      "epoch 10 | loss: 0.02054 | val_logits_ll: 0.02081 |  0:00:15s\n",
      "epoch 20 | loss: 0.01905 | val_logits_ll: 0.01913 |  0:00:30s\n",
      "epoch 30 | loss: 0.01762 | val_logits_ll: 0.01857 |  0:00:46s\n",
      "epoch 40 | loss: 0.01701 | val_logits_ll: 0.01784 |  0:01:01s\n",
      "epoch 50 | loss: 0.01699 | val_logits_ll: 0.01773 |  0:01:16s\n",
      "epoch 60 | loss: 0.01657 | val_logits_ll: 0.01721 |  0:01:31s\n",
      "epoch 70 | loss: 0.01625 | val_logits_ll: 0.01729 |  0:01:47s\n",
      "epoch 80 | loss: 0.01593 | val_logits_ll: 0.01703 |  0:02:02s\n",
      "epoch 90 | loss: 0.01571 | val_logits_ll: 0.01721 |  0:02:17s\n",
      "epoch 100| loss: 0.01557 | val_logits_ll: 0.01708 |  0:02:33s\n",
      "epoch 110| loss: 0.01529 | val_logits_ll: 0.01707 |  0:02:49s\n",
      "\n",
      "Early stopping occured at epoch 118 with best_epoch = 98 and best_val_logits_ll = 0.01687\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "tabnet1_oof, tabnet1_test = modelling_tabnet(tab_train, fn_targets, tab_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:12:16.558098Z",
     "iopub.status.busy": "2020-10-31T02:12:16.556749Z",
     "iopub.status.idle": "2020-10-31T02:12:17.313184Z",
     "shell.execute_reply": "2020-10-31T02:12:17.314492Z"
    },
    "papermill": {
     "duration": 1.050357,
     "end_time": "2020-10-31T02:12:17.314726",
     "exception": false,
     "start_time": "2020-10-31T02:12:16.264369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3624 is out of bounds for axis 0 with size 3624",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3154f9cd6dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtabnet1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabnet1_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtabnet1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabnet1_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcons_test_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheck_tabnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheck_tabnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcons_train_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabnet1_oof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcons_train_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3624 is out of bounds for axis 0 with size 3624"
     ]
    }
   ],
   "source": [
    "tabnet1_test = tabnet1_test.mean(axis=0)\n",
    "tabnet1_test = tabnet1_test[cons_test_index,:]\n",
    "\n",
    "check_tabnet = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "check_tabnet[cons_train_index,:] = tabnet1_oof[cons_train_index,:]\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_tabnet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.288729,
     "end_time": "2020-10-31T02:12:17.921795",
     "exception": false,
     "start_time": "2020-10-31T02:12:17.633066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:12:18.626584Z",
     "iopub.status.busy": "2020-10-31T02:12:18.625502Z",
     "iopub.status.idle": "2020-10-31T02:12:18.630380Z",
     "shell.execute_reply": "2020-10-31T02:12:18.628854Z"
    },
    "papermill": {
     "duration": 0.421478,
     "end_time": "2020-10-31T02:12:18.630527",
     "exception": false,
     "start_time": "2020-10-31T02:12:18.209049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, last_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_hidden_size = 772\n",
    "        self.c_lstm_hidden_size = 100\n",
    "        self.g_layer_num = 1\n",
    "        self.c_layer_num = 1\n",
    "        \n",
    "        self.hidden_dim = 512\n",
    "        self.hidden_dim_c = 10\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.lstm_hidden_size, self.hidden_dim, batch_first=True, bidirectional=True, num_layers=self.g_layer_num)\n",
    "        self.c_lstm = nn.LSTM(self.c_lstm_hidden_size, self.hidden_dim_c, batch_first=True, bidirectional=True, num_layers=self.c_layer_num)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.utils.weight_norm(nn.Linear((self.hidden_dim+self.hidden_dim_c) * 2 , last_num))\n",
    "        self.batch_norm = nn.BatchNorm1d((self.hidden_dim+self.hidden_dim_c) * 2)\n",
    "        \n",
    "    def forward(self, cont_g, cont_c): \n",
    "        cont_g = torch.unsqueeze(cont_g, 1)\n",
    "        h_lstm, lstm_out = self.lstm(cont_g) # h_lstm: 256 * 1 * (2 * 512)\n",
    "        conc_g = h_lstm.view(-1, self.hidden_dim * 2)\n",
    "        \n",
    "        cont_c = torch.unsqueeze(cont_c, 1)\n",
    "        h_lstm_c, lstm_out_c = self.c_lstm(cont_c) # h_lstm: 256 * 1 * (2 * 5)\n",
    "        conc_c = h_lstm_c.view(-1, self.hidden_dim_c * 2)\n",
    "        \n",
    "        conc = torch.cat((conc_g, conc_c),1)\n",
    "        conc = self.batch_norm(conc)\n",
    "        \n",
    "        dropped = self.dropout(conc)\n",
    "        out = self.out(dropped)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:12:19.731462Z",
     "iopub.status.busy": "2020-10-31T02:12:19.705939Z",
     "iopub.status.idle": "2020-10-31T02:12:19.746900Z",
     "shell.execute_reply": "2020-10-31T02:12:19.747448Z"
    },
    "papermill": {
     "duration": 0.6994,
     "end_time": "2020-10-31T02:12:19.747625",
     "exception": false,
     "start_time": "2020-10-31T02:12:19.048225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_epochs = 20\n",
    "n_folds=7\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def seed_everything(seed=1234): \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def modelling_lstm(X_train, y_train, X_test, sample_seed, last_num):\n",
    "    \n",
    "    mskf=MultilabelStratifiedKFold(n_splits = n_folds, shuffle=True, random_state=2)\n",
    "    \n",
    "    seed_everything(seed=sample_seed) \n",
    "    \n",
    "    test_len = X_test.shape[0]\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    X_test_g = torch.tensor(X_test[:,:772], dtype=torch.float32)\n",
    "    X_test_c = torch.tensor(X_test[:,772:872], dtype=torch.float32)\n",
    "\n",
    "    X_test = torch.utils.data.TensorDataset(X_test_g, X_test_c) \n",
    "    test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    oof = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    oof_targets = np.zeros([len(X_train),y_train.shape[1]])\n",
    "    pred_value = np.zeros([test_len, y_train.shape[1]])\n",
    "    scores = []\n",
    "    \n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, y_train)):\n",
    "        print(\"Fold \"+str(fold+1))\n",
    "        X_train2_g = torch.tensor(X_train[train_index,:772], dtype=torch.float32)\n",
    "        X_valid2_g = torch.tensor(X_train[valid_index,:772], dtype=torch.float32)\n",
    "        X_train2_c = torch.tensor(X_train[train_index,772:872], dtype=torch.float32)\n",
    "        X_valid2_c = torch.tensor(X_train[valid_index,772:872], dtype=torch.float32)\n",
    "        \n",
    "        y_train2 = torch.tensor(y_train[train_index], dtype=torch.float32)\n",
    "        y_valid2 = torch.tensor(y_train[valid_index], dtype=torch.float32)\n",
    "            \n",
    "        clf = myLSTM(last_num)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss() \n",
    "\n",
    "        optimizer = optim.Adam(clf.parameters(), lr = 0.01, weight_decay=1e-5) \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        \n",
    "        train = torch.utils.data.TensorDataset(X_train2_g, X_train2_c, y_train2)\n",
    "        valid = torch.utils.data.TensorDataset(X_valid2_g, X_valid2_c, y_valid2)\n",
    "        \n",
    "        clf.to(device)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True) \n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(train_epochs):\n",
    "            start_time = time.time()\n",
    "            clf.train()\n",
    "            avg_loss = 0.\n",
    "            for x_batch_g, x_batch_c, y_batch in tqdm(train_loader, disable=True):\n",
    "                x_batch_g = x_batch_g.to(device)\n",
    "                x_batch_c = x_batch_c.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch_g, x_batch_c) \n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader) \n",
    "                \n",
    "            clf.eval()\n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch_g, x_batch_c, y_batch) in enumerate(valid_loader): \n",
    "                x_batch_g = x_batch_g.to(device)\n",
    "                x_batch_c = x_batch_c.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = clf(x_batch_g, x_batch_c).detach()\n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                \n",
    "            elapsed_time = time.time() - start_time \n",
    "            scheduler.step(avg_val_loss)\n",
    "                    \n",
    "            if avg_val_loss < best_val_loss:\n",
    "                stop_counts = 0\n",
    "                best_val_loss = avg_val_loss\n",
    "                print('Best model: Epoch {} \\t loss={:.6f} \\t val_loss={:.6f} \\t time={:.2f}s'.format(\n",
    "                    epoch + 1, avg_loss, avg_val_loss, elapsed_time))\n",
    "                torch.save(clf.state_dict(), 'best-model-parameters.pt')\n",
    "                \n",
    "        pred_model = myLSTM(last_num)\n",
    "        pred_model.load_state_dict(torch.load('best-model-parameters.pt'))\n",
    "        pred_model.eval()\n",
    "        \n",
    "        # validation check ----------------\n",
    "        oof_epoch = np.zeros([X_valid2_g.size(0), y_train.shape[1]])\n",
    "        target_epoch = np.zeros([X_valid2_g.size(0), y_train.shape[1]])\n",
    "        for i, (x_batch_g, x_batch_c, y_batch) in enumerate(valid_loader): \n",
    "                y_pred = pred_model(x_batch_g, x_batch_c).sigmoid().detach()\n",
    "                oof_epoch[i * batch_size:(i+1) * batch_size,:] = y_pred.cpu().numpy()\n",
    "                target_epoch[i * batch_size:(i+1) * batch_size,:] = y_batch.cpu().numpy()\n",
    "        print(\"Fold {} log loss: {}\".format(fold+1, mean_log_loss(target_epoch, oof_epoch)))\n",
    "        scores.append(mean_log_loss(target_epoch, oof_epoch))\n",
    "        oof[valid_index,:] = oof_epoch\n",
    "        oof_targets[valid_index,:] = target_epoch\n",
    "        #-----------------------------------\n",
    "        \n",
    "        # test predcition --------------\n",
    "        test_preds = np.zeros([test_len, y_train.shape[1]])\n",
    "        for i, (x_batch_g, x_batch_c, ) in enumerate(test_loader): \n",
    "            y_pred = pred_model(x_batch_g, x_batch_c).sigmoid().detach()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred.cpu().numpy()\n",
    "        pred_value += test_preds / n_folds\n",
    "        # ------------------------------\n",
    "        \n",
    "    print(\"Seed {}\".format(seed_))\n",
    "    for i, ele in enumerate(scores):\n",
    "        print(\"Fold {} log loss: {}\".format(i+1, scores[i]))\n",
    "    print(\"Total log loss: {}\".format(mean_log_loss(oof_targets, oof)))\n",
    "\n",
    "    return oof, pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:12:20.330934Z",
     "iopub.status.busy": "2020-10-31T02:12:20.329628Z",
     "iopub.status.idle": "2020-10-31T02:14:49.338889Z",
     "shell.execute_reply": "2020-10-31T02:14:49.339576Z"
    },
    "papermill": {
     "duration": 149.30804,
     "end_time": "2020-10-31T02:14:49.339763",
     "exception": false,
     "start_time": "2020-10-31T02:12:20.031723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best model: Epoch 1 \t loss=0.135718 \t val_loss=0.019528 \t time=0.84s\n",
      "Best model: Epoch 2 \t loss=0.018420 \t val_loss=0.018160 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.017349 \t val_loss=0.017843 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.016957 \t val_loss=0.017404 \t time=0.84s\n",
      "Best model: Epoch 5 \t loss=0.016630 \t val_loss=0.017377 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.016477 \t val_loss=0.017141 \t time=0.84s\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Best model: Epoch 11 \t loss=0.014614 \t val_loss=0.016299 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.013351 \t val_loss=0.016201 \t time=0.85s\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 1 log loss: 0.016390824321679393\n",
      "Fold 2\n",
      "Best model: Epoch 1 \t loss=0.134602 \t val_loss=0.019511 \t time=0.99s\n",
      "Best model: Epoch 2 \t loss=0.018470 \t val_loss=0.017900 \t time=0.84s\n",
      "Best model: Epoch 3 \t loss=0.017539 \t val_loss=0.017515 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.017001 \t val_loss=0.017395 \t time=0.85s\n",
      "Best model: Epoch 5 \t loss=0.016759 \t val_loss=0.017159 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.016477 \t val_loss=0.017014 \t time=0.84s\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Best model: Epoch 11 \t loss=0.014525 \t val_loss=0.016090 \t time=1.42s\n",
      "Best model: Epoch 12 \t loss=0.013265 \t val_loss=0.015956 \t time=0.85s\n",
      "Best model: Epoch 13 \t loss=0.012534 \t val_loss=0.015913 \t time=1.22s\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 2 log loss: 0.01608083360904913\n",
      "Fold 3\n",
      "Best model: Epoch 1 \t loss=0.136787 \t val_loss=0.019525 \t time=0.86s\n",
      "Best model: Epoch 2 \t loss=0.018355 \t val_loss=0.018213 \t time=1.08s\n",
      "Best model: Epoch 3 \t loss=0.017431 \t val_loss=0.017888 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.017021 \t val_loss=0.017419 \t time=0.84s\n",
      "Best model: Epoch 5 \t loss=0.016720 \t val_loss=0.017295 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.016567 \t val_loss=0.017270 \t time=0.88s\n",
      "Best model: Epoch 10 \t loss=0.016496 \t val_loss=0.017260 \t time=0.87s\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Best model: Epoch 15 \t loss=0.014835 \t val_loss=0.016471 \t time=0.84s\n",
      "Best model: Epoch 16 \t loss=0.013574 \t val_loss=0.016306 \t time=0.83s\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 3 log loss: 0.01637301068210786\n",
      "Fold 4\n",
      "Best model: Epoch 1 \t loss=0.137411 \t val_loss=0.019607 \t time=0.95s\n",
      "Best model: Epoch 2 \t loss=0.018484 \t val_loss=0.018296 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.017531 \t val_loss=0.017762 \t time=1.00s\n",
      "Best model: Epoch 4 \t loss=0.016972 \t val_loss=0.017700 \t time=0.82s\n",
      "Best model: Epoch 5 \t loss=0.016802 \t val_loss=0.017389 \t time=0.86s\n",
      "Best model: Epoch 6 \t loss=0.016484 \t val_loss=0.017332 \t time=0.84s\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Best model: Epoch 11 \t loss=0.014833 \t val_loss=0.016500 \t time=0.84s\n",
      "Best model: Epoch 12 \t loss=0.013549 \t val_loss=0.016367 \t time=0.83s\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 4 log loss: 0.016465688190684644\n",
      "Fold 5\n",
      "Best model: Epoch 1 \t loss=0.142790 \t val_loss=0.019862 \t time=0.84s\n",
      "Best model: Epoch 2 \t loss=0.018496 \t val_loss=0.018264 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.017529 \t val_loss=0.018238 \t time=0.83s\n",
      "Best model: Epoch 4 \t loss=0.017033 \t val_loss=0.017798 \t time=0.99s\n",
      "Best model: Epoch 5 \t loss=0.016714 \t val_loss=0.017563 \t time=0.84s\n",
      "Best model: Epoch 6 \t loss=0.016435 \t val_loss=0.017400 \t time=0.83s\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Best model: Epoch 11 \t loss=0.014585 \t val_loss=0.016502 \t time=1.25s\n",
      "Best model: Epoch 12 \t loss=0.013366 \t val_loss=0.016365 \t time=1.75s\n",
      "Best model: Epoch 13 \t loss=0.012681 \t val_loss=0.016328 \t time=1.05s\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 5 log loss: 0.016319925050251264\n",
      "Fold 6\n",
      "Best model: Epoch 1 \t loss=0.138341 \t val_loss=0.019669 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.018420 \t val_loss=0.018329 \t time=0.83s\n",
      "Best model: Epoch 3 \t loss=0.017414 \t val_loss=0.018039 \t time=0.86s\n",
      "Best model: Epoch 4 \t loss=0.017000 \t val_loss=0.017703 \t time=0.83s\n",
      "Best model: Epoch 5 \t loss=0.016632 \t val_loss=0.017457 \t time=1.01s\n",
      "Best model: Epoch 6 \t loss=0.016421 \t val_loss=0.017307 \t time=0.83s\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Best model: Epoch 11 \t loss=0.014640 \t val_loss=0.016611 \t time=0.83s\n",
      "Best model: Epoch 12 \t loss=0.013353 \t val_loss=0.016457 \t time=1.10s\n",
      "Best model: Epoch 13 \t loss=0.012635 \t val_loss=0.016438 \t time=0.83s\n",
      "Best model: Epoch 14 \t loss=0.012064 \t val_loss=0.016438 \t time=0.83s\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 6 log loss: 0.01656790463571591\n",
      "Fold 7\n",
      "Best model: Epoch 1 \t loss=0.135162 \t val_loss=0.019454 \t time=0.83s\n",
      "Best model: Epoch 2 \t loss=0.018314 \t val_loss=0.018119 \t time=1.17s\n",
      "Best model: Epoch 3 \t loss=0.017485 \t val_loss=0.017671 \t time=1.09s\n",
      "Best model: Epoch 4 \t loss=0.017097 \t val_loss=0.017480 \t time=0.90s\n",
      "Best model: Epoch 5 \t loss=0.016713 \t val_loss=0.017439 \t time=0.83s\n",
      "Best model: Epoch 6 \t loss=0.016651 \t val_loss=0.017260 \t time=1.01s\n",
      "Best model: Epoch 8 \t loss=0.016499 \t val_loss=0.017223 \t time=0.83s\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Best model: Epoch 13 \t loss=0.014688 \t val_loss=0.016321 \t time=1.14s\n",
      "Best model: Epoch 14 \t loss=0.013418 \t val_loss=0.016160 \t time=0.83s\n",
      "Best model: Epoch 15 \t loss=0.012646 \t val_loss=0.016136 \t time=0.83s\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Fold 7 log loss: 0.016024174881964545\n",
      "Seed 4\n",
      "Fold 1 log loss: 0.016390824321679393\n",
      "Fold 2 log loss: 0.01608083360904913\n",
      "Fold 3 log loss: 0.01637301068210786\n",
      "Fold 4 log loss: 0.016465688190684644\n",
      "Fold 5 log loss: 0.016319925050251264\n",
      "Fold 6 log loss: 0.01656790463571591\n",
      "Fold 7 log loss: 0.016024174881964545\n",
      "Total log loss: 0.016317480935064667\n"
     ]
    }
   ],
   "source": [
    "lstm1_oof, lstm1_test = modelling_lstm(lstm_train, fn_targets, lstm_test, 0, fn_targets.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:14:50.007125Z",
     "iopub.status.busy": "2020-10-31T02:14:50.005982Z",
     "iopub.status.idle": "2020-10-31T02:14:51.765201Z",
     "shell.execute_reply": "2020-10-31T02:14:51.765801Z"
    },
    "papermill": {
     "duration": 2.091391,
     "end_time": "2020-10-31T02:14:51.765967",
     "exception": false,
     "start_time": "2020-10-31T02:14:49.674576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015038887694751035\n"
     ]
    }
   ],
   "source": [
    "check_lstm = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "check_lstm[cons_train_index,:] = lstm1_oof\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_lstm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.31824,
     "end_time": "2020-10-31T02:14:52.402572",
     "exception": false,
     "start_time": "2020-10-31T02:14:52.084332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:14:53.060539Z",
     "iopub.status.busy": "2020-10-31T02:14:53.059469Z",
     "iopub.status.idle": "2020-10-31T02:23:49.577670Z",
     "shell.execute_reply": "2020-10-31T02:23:49.576974Z"
    },
    "papermill": {
     "duration": 536.858985,
     "end_time": "2020-10-31T02:23:49.577853",
     "exception": false,
     "start_time": "2020-10-31T02:14:52.718868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b773bd57c2e447cfa599ab4f56c95dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=206.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_STARTS = 1\n",
    "N_SPLITS = 5\n",
    "\n",
    "svm0_oof = np.zeros([len(fn_train), fn_targets.shape[1]])\n",
    "svm0_test = np.zeros([len(fn_test), fn_targets.shape[1]])\n",
    "\n",
    "svm1_test = np.zeros([len(fn_test),fn_targets.shape[1]])\n",
    "svm1_oof = np.zeros([fn_targets.shape[0],fn_targets.shape[1]]) \n",
    "\n",
    "for ind in tqdm(range(fn_targets.shape[1])):\n",
    "    ind_target_sum = fn_targets[:, ind].sum()\n",
    "    if ind_target_sum >= N_SPLITS:\n",
    "        for seed in range(N_STARTS):\n",
    "            skf = StratifiedKFold(n_splits = N_SPLITS, random_state = seed, shuffle = True)\n",
    "\n",
    "            for n, (train_index, val_index) in enumerate(skf.split(fn_train, fn_targets[:,ind])):\n",
    "                \n",
    "                x_tr, x_val = fn_train[train_index], fn_train[val_index]\n",
    "                y_tr, y_val = fn_targets[train_index,ind], fn_targets[val_index,ind]\n",
    "\n",
    "                model = SVC(C = 40, cache_size = 2000)\n",
    "                model.fit(x_tr, y_tr)\n",
    "                svm0_test[:, ind] += model.decision_function(fn_test) / (N_SPLITS * N_STARTS)\n",
    "                svm0_oof[val_index, ind] += model.decision_function(x_val) / N_STARTS\n",
    "\n",
    "        for seed in range(N_STARTS):\n",
    "            skf = StratifiedKFold(n_splits = N_SPLITS, random_state = seed, shuffle = True)\n",
    "            \n",
    "            for n, (train_index, val_index) in enumerate(skf.split(svm0_oof, fn_targets[:,ind])):\n",
    "\n",
    "                x_tr, x_val = svm0_oof[train_index, ind].reshape(-1, 1), svm0_oof[val_index, ind].reshape(-1, 1)\n",
    "                y_tr, y_val = fn_targets[train_index,ind], fn_targets[val_index,ind]\n",
    "\n",
    "                model = LogisticRegression(C = 35, max_iter = 1000)\n",
    "                model.fit(x_tr, y_tr)\n",
    "                svm1_test[:, ind] += model.predict_proba(svm0_test[:, ind].reshape(-1, 1))[:, 1] / (N_SPLITS * N_STARTS)\n",
    "                svm1_oof[val_index, ind] += model.predict_proba(x_val)[:, 1] / N_STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:23:50.550370Z",
     "iopub.status.busy": "2020-10-31T02:23:50.548747Z",
     "iopub.status.idle": "2020-10-31T02:23:52.151912Z",
     "shell.execute_reply": "2020-10-31T02:23:52.153117Z"
    },
    "papermill": {
     "duration": 2.041755,
     "end_time": "2020-10-31T02:23:52.153347",
     "exception": false,
     "start_time": "2020-10-31T02:23:50.111592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF log loss:  0.015414626688103106\n"
     ]
    }
   ],
   "source": [
    "check_svm = np.zeros([targets.shape[0], targets.shape[1]-1])\n",
    "check_svm[cons_train_index,:] = svm1_oof\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.331494,
     "end_time": "2020-10-31T02:23:52.955329",
     "exception": false,
     "start_time": "2020-10-31T02:23:52.623835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.322031,
     "end_time": "2020-10-31T02:23:53.601840",
     "exception": false,
     "start_time": "2020-10-31T02:23:53.279809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- https://www.kaggle.com/ipythonx/optimizing-metrics-out-of-fold-weights-ensemble\n",
    "- https://www.kaggle.com/hsperr/finding-ensamble-weights\n",
    "- https://stackoverflow.com/questions/18767657/how-do-i-use-a-minimization-function-in-scipy-with-constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-31T02:23:54.287549Z",
     "iopub.status.busy": "2020-10-31T02:23:54.286324Z",
     "iopub.status.idle": "2020-10-31T02:31:18.398433Z",
     "shell.execute_reply": "2020-10-31T02:31:18.397795Z"
    },
    "papermill": {
     "duration": 444.470012,
     "end_time": "2020-10-31T02:31:18.398585",
     "exception": false,
     "start_time": "2020-10-31T02:23:53.928573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.00511688, Weights: [0.58445078 0.05610932 0.27163701 0.08780289]\n",
      "Score: 0.00636059, Weights: [0.2801021  0.31739321 0.09903177 0.30347291]\n",
      "Score: 0.00841596, Weights: [0.24898422 0.02156299 0.57239401 0.15705878]\n",
      "Score: 0.04680968, Weights: [2.77555756e-17 2.44189302e-01 2.77813821e-01 4.77996877e-01]\n",
      "Score: 0.06797083, Weights: [1.49186219e-16 3.46944695e-17 4.20467953e-01 5.79532047e-01]\n",
      "Score: 0.02159649, Weights: [0.03480886 0.26124571 0.45720713 0.2467383 ]\n",
      "Score: 0.01614989, Weights: [0.08712218 0.01871138 0.4909084  0.40325804]\n",
      "Score: 0.02667612, Weights: [0.37465643 0.17055987 0.18939249 0.26539121]\n",
      "Score: 0.00126765, Weights: [0.31334539 0.36404968 0.04689026 0.27571467]\n",
      "Score: 0.05428468, Weights: [0.00224494 0.09033775 0.03062222 0.87679509]\n",
      "Score: 0.07913877, Weights: [0.         0.15293438 0.34228569 0.50477992]\n",
      "Score: 0.01043866, Weights: [4.01000573e-01 2.93149879e-02 4.85722573e-17 5.69684439e-01]\n",
      "Score: 0.00081821, Weights: [5.64997400e-01 4.35002600e-01 2.42861287e-17 6.24500451e-17]\n",
      "Score: 0.00964973, Weights: [0.3286739  0.51440696 0.         0.15691914]\n",
      "Score: 0.00466826, Weights: [0.34495138 0.34331745 0.26563571 0.04609547]\n",
      "Score: 0.00449359, Weights: [0.12942952 0.52760129 0.0761971  0.26677208]\n",
      "Score: 0.01507401, Weights: [0.41097896 0.19242597 0.12631305 0.27028202]\n",
      "Score: 0.02529795, Weights: [0.16310742 0.37326237 0.10691976 0.35671045]\n",
      "Score: 0.02329052, Weights: [0.23839081 0.33064184 0.08964666 0.34132069]\n",
      "Score: 0.01190104, Weights: [0.20560572 0.05956025 0.06423907 0.67059496]\n",
      "Score: 0.01190006, Weights: [0.05983494 0.2979796  0.12831094 0.51387452]\n",
      "Score: 0.02020453, Weights: [0.45582852 0.23174573 0.05212808 0.26029767]\n",
      "Score: 0.00257601, Weights: [0.07911723 0.20892801 0.57322286 0.1387319 ]\n",
      "Score: 0.01287685, Weights: [0.38810571 0.25972127 0.17146703 0.180706  ]\n",
      "Score: 0.00456722, Weights: [0.70091186 0.05052556 0.04180401 0.20675857]\n",
      "Score: 0.0047117, Weights: [0.09758583 0.18440229 0.40252329 0.31548859]\n",
      "Score: 0.00454731, Weights: [0.08405232 0.20599332 0.26662332 0.44333104]\n",
      "Score: 0.00630707, Weights: [0.63913389 0.13274736 0.05656363 0.17155512]\n",
      "Score: 0.02131001, Weights: [0.18289137 0.26267302 0.280815   0.27362061]\n",
      "Score: 0.01177369, Weights: [0.10560396 0.0173986  0.44154804 0.4354494 ]\n",
      "Score: 0.00806065, Weights: [0.07099924 0.42957969 0.06783026 0.43159082]\n",
      "Score: 0.01468525, Weights: [0.37336804 0.21403226 0.05491605 0.35768365]\n",
      "Score: 0.01477681, Weights: [0.28577918 0.22513257 0.28126054 0.20782772]\n",
      "Score: 0.00184138, Weights: [0.25948557 0.39103718 0.34000633 0.00947091]\n",
      "Score: 0.0007191, Weights: [0.03914992 0.33339038 0.52561869 0.101841  ]\n",
      "Score: 0.00088238, Weights: [0.95439029 0.04560971 0.         0.        ]\n",
      "Score: 0.02055438, Weights: [6.59194921e-17 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      "Score: 0.00304074, Weights: [6.76963182e-01 3.23036818e-01 2.77555756e-17 1.11022302e-16]\n",
      "Score: 0.00910282, Weights: [0.2273309  0.05991853 0.         0.71275057]\n",
      "Score: 0.00234059, Weights: [0.40692911 0.37890979 0.04434913 0.16981196]\n",
      "Score: 0.01825325, Weights: [0.34370868 0.19770671 0.13597464 0.32260996]\n",
      "Score: 0.02211905, Weights: [0.27190449 0.14951344 0.32099052 0.25759155]\n",
      "Score: 0.01133288, Weights: [0.08530424 0.22245285 0.34594303 0.34629988]\n",
      "Score: 0.0481408, Weights: [0.         0.4757141  0.16690217 0.35738372]\n",
      "Score: 0.02490724, Weights: [0.12653361 0.30427423 0.20490404 0.36428812]\n",
      "Score: 0.03028263, Weights: [0.36228926 0.34669472 0.16250655 0.12850947]\n",
      "Score: 0.00188868, Weights: [0.1032824  0.19137315 0.24051597 0.46482848]\n",
      "Score: 0.00653726, Weights: [8.31566174e-01 1.07448505e-17 1.37732110e-02 1.54660615e-01]\n",
      "Score: 0.00855555, Weights: [0.28555722 0.13557301 0.26310155 0.31576822]\n",
      "Score: 0.01975131, Weights: [0.23544712 0.27781277 0.37312364 0.11361647]\n",
      "Score: 0.00842273, Weights: [0.25241356 0.16232286 0.45214953 0.13311405]\n",
      "Score: 0.01235291, Weights: [0.3796144  0.31577295 0.         0.30461265]\n",
      "Score: 0.00698085, Weights: [0.74503015 0.11288933 0.         0.14208052]\n",
      "Score: 0.00257654, Weights: [0.42876563 0.0239217  0.24074165 0.30657103]\n",
      "Score: 0.06361968, Weights: [1.60461920e-17 6.93889390e-18 7.20459063e-02 9.27954094e-01]\n",
      "Score: 0.01327553, Weights: [0.21504674 0.1839103  0.30519547 0.29584749]\n",
      "Score: 0.01650923, Weights: [0.20271203 0.20761587 0.28486764 0.30480445]\n",
      "Score: 0.01183075, Weights: [0.12870235 0.25923196 0.29426704 0.31779865]\n",
      "Score: 0.0113647, Weights: [0.20220592 0.33779609 0.14765975 0.31233825]\n",
      "Score: 0.00642592, Weights: [0.09636424 0.45937188 0.07185246 0.37241143]\n",
      "Score: 0.00461164, Weights: [0.2419728  0.28027899 0.14596269 0.33178553]\n",
      "Score: 0.02870204, Weights: [0.18520337 0.32930684 0.09671506 0.38877473]\n",
      "Score: 0.00646711, Weights: [0.19065398 0.29958127 0.22476843 0.28499632]\n",
      "Score: 0.01703456, Weights: [1.98506243e-01 2.15970509e-01 2.77555756e-17 5.85523248e-01]\n",
      "Score: 0.01672727, Weights: [0.50161747 0.043329   0.26300038 0.19205315]\n",
      "Score: 0.00181927, Weights: [0.71098687 0.         0.         0.28901313]\n",
      "Score: 0.01289917, Weights: [0.06771165 0.39125358 0.34156342 0.19947135]\n",
      "Score: 0.01501209, Weights: [0.10949472 0.4368072  0.01575382 0.43794426]\n",
      "Score: 0.01648244, Weights: [0.34622848 0.32900497 0.04883703 0.27592952]\n",
      "Score: 0.00259978, Weights: [0.14709419 0.28257258 0.27417646 0.29615677]\n",
      "Score: 0.00831286, Weights: [0.         0.30468516 0.39048104 0.30483381]\n",
      "Score: 0.08888497, Weights: [0.         0.25429416 0.111866   0.63383984]\n",
      "Score: 0.02835558, Weights: [2.77555756e-17 1.93610388e-01 2.46833326e-01 5.59556286e-01]\n",
      "Score: 0.0087063, Weights: [0.3903646  0.26421713 0.11315699 0.23226128]\n",
      "Score: 0.00838931, Weights: [0.26442955 0.40206629 0.2550079  0.07849626]\n",
      "Score: 0.00256968, Weights: [0.1819998  0.30644941 0.31073194 0.20081885]\n",
      "Score: 0.01466111, Weights: [0.30480044 0.29659048 0.05578777 0.34282131]\n",
      "Score: 0.07909837, Weights: [0.         0.13549509 0.06034311 0.8041618 ]\n",
      "Score: 0.03313813, Weights: [0.36583894 0.29184142 0.32750504 0.0148146 ]\n",
      "Score: 0.08524504, Weights: [0.         0.18541519 0.0421135  0.77247131]\n",
      "Score: 0.01409098, Weights: [0.         0.20025673 0.         0.79974327]\n",
      "Score: 0.00267545, Weights: [0.17201955 0.02486037 0.35453994 0.44858014]\n",
      "Score: 0.00066299, Weights: [0.44685493 0.28942419 0.04208174 0.22163914]\n",
      "Score: 0.03892565, Weights: [1.38777865e-17 1.08368335e-01 0.00000000e+00 8.91631665e-01]\n",
      "Score: 0.01413351, Weights: [0.50629308 0.16471421 0.05162092 0.27737179]\n",
      "Score: 0.01057695, Weights: [0.         0.2847399  0.42135292 0.29390718]\n",
      "Score: 0.00197349, Weights: [0.76012953 0.         0.         0.23987047]\n",
      "Score: 0.00814265, Weights: [0.13837003 0.23428311 0.28079142 0.34655543]\n",
      "Score: 0.00919345, Weights: [0.09025609 0.26644998 0.07239018 0.57090374]\n",
      "Score: 0.01761722, Weights: [1.38777878e-17 2.77555756e-17 7.24088018e-02 9.27591198e-01]\n",
      "Score: 0.0015039, Weights: [0.69012903 0.         0.         0.30987097]\n",
      "Score: 0.00653225, Weights: [0.32796282 0.31492514 0.06563259 0.29147945]\n",
      "Score: 0.00753004, Weights: [0.24928323 0.2691912  0.33079138 0.15073418]\n",
      "Score: 0.02925833, Weights: [0.20854044 0.1748858  0.57535332 0.04122044]\n",
      "Score: 0.04231794, Weights: [0.         0.27340998 0.15667641 0.56991361]\n",
      "Score: 0.0094842, Weights: [0.16929957 0.14470161 0.04855167 0.63744715]\n",
      "Score: 0.01422797, Weights: [0.20750361 0.4244783  0.10082131 0.26719678]\n",
      "Score: 0.00459474, Weights: [0.23755412 0.27134774 0.1502391  0.34085904]\n",
      "Score: 0.02179327, Weights: [0.5130395  0.09141232 0.08575643 0.30979175]\n",
      "Score: 0.08077895, Weights: [0.         0.03636757 0.3799221  0.58371033]\n",
      "Score: 0.00646207, Weights: [0.29725577 0.28538867 0.18031429 0.23704127]\n",
      "Score: 0.00993426, Weights: [0.31193512 0.16865281 0.1762478  0.34316427]\n",
      "Score: 0.02138771, Weights: [0.30859517 0.34810176 0.27626592 0.06703715]\n",
      "Score: 0.00989264, Weights: [0.09711329 0.4197973  0.         0.48308941]\n",
      "Score: 0.01794551, Weights: [0.20657087 0.1575959  0.30067188 0.33516135]\n",
      "Score: 0.05731831, Weights: [0.         0.29136194 0.28087398 0.42776407]\n",
      "Score: 0.00351066, Weights: [0.84746232 0.02068337 0.02707206 0.10478225]\n",
      "Score: 0.00748671, Weights: [8.74238160e-01 6.67832241e-02 1.38777878e-17 5.89786164e-02]\n",
      "Score: 0.02058932, Weights: [0.20240028 0.26637304 0.34027282 0.19095385]\n",
      "Score: 0.00940535, Weights: [0.00000000e+00 8.45494129e-02 3.59489141e-17 9.15450587e-01]\n",
      "Score: 0.00707081, Weights: [0.09341222 0.32784144 0.36777087 0.21097547]\n",
      "Score: 0.0085366, Weights: [0.21796513 0.28778431 0.20589557 0.288355  ]\n",
      "Score: 0.00684476, Weights: [0.48538602 0.29409573 0.00374681 0.21677144]\n",
      "Score: 0.01039129, Weights: [0.17788667 0.29096312 0.27673148 0.25441872]\n",
      "Score: 0.01887335, Weights: [0.25061984 0.32563795 0.23018744 0.19355476]\n",
      "Score: 0.00996237, Weights: [0.31047139 0.57882486 0.02536571 0.08533804]\n",
      "Score: 0.011334, Weights: [5.55111512e-17 1.61244804e-01 1.92771660e-01 6.45983536e-01]\n",
      "Score: 0.01335713, Weights: [0.43407251 0.13749384 0.00054192 0.42789173]\n",
      "Score: 0.01042537, Weights: [4.40117294e-01 1.05942393e-02 2.34076642e-18 5.49288467e-01]\n",
      "Score: 0.01497703, Weights: [0.         0.34305657 0.         0.65694343]\n",
      "Score: 0.00255869, Weights: [0.51159895 0.03710015 0.27380559 0.17749531]\n",
      "Score: 0.00257385, Weights: [0.12091543 0.49403035 0.09834233 0.28671189]\n",
      "Score: 0.0188796, Weights: [0.33263187 0.09154788 0.27271483 0.30310543]\n",
      "Score: 0.00467915, Weights: [0.1535281  0.265691   0.03701889 0.54376201]\n",
      "Score: 0.01754721, Weights: [1.57352543e-01 4.21637237e-01 2.77555756e-17 4.21010220e-01]\n",
      "Score: 0.00222405, Weights: [0.12061863 0.26316409 0.03383073 0.58238654]\n",
      "Score: 0.00254074, Weights: [9.21644258e-01 5.51293508e-03 8.67361738e-19 7.28428068e-02]\n",
      "Score: 0.00702771, Weights: [5.55111512e-17 1.45916181e-01 1.76030925e-01 6.78052894e-01]\n",
      "Score: 0.02193358, Weights: [0.29908878 0.13987832 0.44161102 0.11942188]\n",
      "Score: 0.00828733, Weights: [0.23531262 0.30161184 0.23405896 0.22901658]\n",
      "Score: 0.00462048, Weights: [0.24815591 0.04212629 0.41036588 0.29935191]\n",
      "Score: 0.02448054, Weights: [0.04670874 0.38245277 0.13803043 0.43280806]\n",
      "Score: 0.00541667, Weights: [0.20039093 0.34083951 0.3389064  0.11986316]\n",
      "Score: 0.01459591, Weights: [3.8732307e-01 0.0000000e+00 5.6378513e-18 6.1267693e-01]\n",
      "Score: 0.01511592, Weights: [0.25249738 0.21554287 0.4720314  0.05992834]\n",
      "Score: 0.01148146, Weights: [0.22198999 0.26840783 0.04947569 0.46012649]\n",
      "Score: 0.03123152, Weights: [3.29597460e-17 2.50335488e-02 2.67813722e-01 7.07152729e-01]\n",
      "Score: 0.00259504, Weights: [0.23745639 0.09936289 0.36062971 0.30255101]\n",
      "Score: 0.00883103, Weights: [0.35025347 0.19953944 0.28444032 0.16576676]\n",
      "Score: 0.00400578, Weights: [0.3222973  0.12621523 0.18832841 0.36315906]\n",
      "Score: 0.00881123, Weights: [0.11430781 0.24522832 0.33147299 0.30899088]\n",
      "Score: 0.00287799, Weights: [0.04657193 0.38848476 0.31646461 0.2484787 ]\n",
      "Score: 0.00463118, Weights: [0.15984373 0.29994021 0.28689791 0.25331815]\n",
      "Score: 0.01841534, Weights: [0.18054848 0.06779773 0.34092314 0.41073064]\n",
      "Score: 0.0272103, Weights: [0.33946938 0.08617899 0.1417729  0.43257873]\n",
      "Score: 0.01222396, Weights: [0.18439648 0.36744998 0.31814026 0.13001327]\n",
      "Score: 0.00873081, Weights: [0.15515686 0.26075292 0.10367871 0.48041152]\n",
      "Score: 0.00798797, Weights: [0.36047991 0.47664556 0.05714888 0.10572565]\n",
      "Score: 0.01549495, Weights: [0.37250521 0.33194372 0.         0.29555107]\n",
      "Score: 0.01673772, Weights: [5.20417101e-18 2.47905157e-01 7.72593147e-02 6.74835529e-01]\n",
      "Score: 0.00588134, Weights: [0.12413473 0.35916324 0.01570817 0.50099385]\n",
      "Score: 0.05986911, Weights: [0.15245075 0.33955471 0.08749806 0.42049648]\n",
      "Score: 0.00846518, Weights: [0.25763127 0.29983026 0.11139452 0.33114394]\n",
      "Score: 0.02320383, Weights: [1.20477293e-01 0.00000000e+00 6.93889390e-18 8.79522707e-01]\n",
      "Score: 0.00939291, Weights: [0.39421328 0.10264596 0.35177969 0.15136107]\n",
      "Score: 0.01673645, Weights: [0.22443848 0.39513769 0.28720364 0.09322018]\n",
      "Score: 0.02759382, Weights: [0.24499238 0.22864427 0.31614807 0.21021527]\n",
      "Score: 0.02234931, Weights: [0.         0.28487096 0.01636124 0.6987678 ]\n",
      "Score: 0.00929962, Weights: [0.04558181 0.46884239 0.44874314 0.03683265]\n",
      "Score: 0.02751278, Weights: [1.99805250e-01 3.81639165e-17 0.00000000e+00 8.00194750e-01]\n",
      "Score: 0.00489924, Weights: [0.30531872 0.3264068  0.2677238  0.10055068]\n",
      "Score: 0.01160354, Weights: [0.30347727 0.27849402 0.10677567 0.31125304]\n",
      "Score: 0.02399446, Weights: [0.2198949  0.18175827 0.25963348 0.33871336]\n",
      "Score: 0.00214159, Weights: [0.         0.         0.70399715 0.29600285]\n",
      "Score: 0.01479182, Weights: [0.48936939 0.24967757 0.16961225 0.09134079]\n",
      "Score: 0.00237913, Weights: [0.21530463 0.27573046 0.168147   0.3408179 ]\n",
      "Score: 0.02272846, Weights: [0.00000000e+00 3.99715453e-01 1.38777878e-16 6.00284547e-01]\n",
      "Score: 0.00657422, Weights: [0.13933574 0.32377115 0.35573895 0.18115416]\n",
      "Score: 0.01707806, Weights: [0.24297046 0.48274602 0.13389218 0.14039135]\n",
      "Score: 0.00565542, Weights: [3.31412509e-01 1.36307204e-01 6.93889390e-18 5.32280287e-01]\n",
      "Score: 0.00436209, Weights: [0.18384083 0.43771511 0.22318108 0.15526298]\n",
      "Score: 0.00802228, Weights: [0.5891732  0.05786545 0.01634874 0.33661261]\n",
      "Score: 0.00247785, Weights: [0.32146854 0.27758984 0.15474681 0.2461948 ]\n",
      "Score: 0.00766935, Weights: [6.13202769e-01 1.28675318e-01 2.77555756e-17 2.58121913e-01]\n",
      "Score: 0.00921142, Weights: [0.35729348 0.19429038 0.155622   0.29279415]\n",
      "Score: 0.00812553, Weights: [0.3699829  0.07533654 0.20339962 0.35128093]\n",
      "Score: 0.05690178, Weights: [1.21430643e-17 2.19065602e-02 3.54417327e-01 6.23676113e-01]\n",
      "Score: 0.08430013, Weights: [0.         0.19072986 0.35583597 0.45343417]\n",
      "Score: 0.01379822, Weights: [0.11166033 0.04310286 0.77478569 0.07045112]\n",
      "Score: 0.01176326, Weights: [0.51952413 0.01772368 0.43357112 0.02918107]\n",
      "Score: 0.01169814, Weights: [0.38710738 0.4118886  0.11093552 0.0900685 ]\n",
      "Score: 0.00866285, Weights: [0.28769316 0.30774962 0.38055059 0.02400663]\n",
      "Score: 0.06327219, Weights: [0.         0.         0.34978855 0.65021145]\n",
      "Score: 0.00842821, Weights: [0.39508308 0.37893937 0.08048681 0.14549074]\n",
      "Score: 0.013785, Weights: [0.20998981 0.09223449 0.         0.6977757 ]\n",
      "Score: 0.00248648, Weights: [0.01355136 0.55612044 0.40990249 0.02042571]\n",
      "Score: 0.00487576, Weights: [0.32666976 0.30710185 0.22351715 0.14271124]\n",
      "Score: 0.01791514, Weights: [0.17942973 0.22054749 0.40611573 0.19390705]\n",
      "Score: 0.00264821, Weights: [0.30218375 0.40303925 0.02576689 0.26901011]\n",
      "Score: 0.00666361, Weights: [0.33039809 0.36866295 0.08166566 0.21927329]\n",
      "Score: 0.01028782, Weights: [0.17121917 0.27363053 0.14979146 0.40535885]\n",
      "Score: 0.01025658, Weights: [0.26656607 0.41344377 0.17767488 0.14231527]\n",
      "Score: 0.00285349, Weights: [0.51253748 0.02249026 0.45024285 0.01472941]\n",
      "Score: 0.01125142, Weights: [0.03785889 0.24885096 0.30834785 0.4049423 ]\n",
      "Score: 0.01296761, Weights: [0.2318312  0.16484075 0.         0.60332805]\n",
      "Score: 0.00648125, Weights: [0.14343014 0.27577763 0.43004953 0.15074271]\n",
      "Score: 0.00231813, Weights: [0.62448635 0.25053123 0.10990304 0.01507938]\n",
      "Score: 0.00589041, Weights: [7.88413895e-01 3.39384114e-02 5.55111512e-17 1.77647694e-01]\n",
      "Score: 0.0149533, Weights: [0.10774049 0.2360204  0.33704196 0.31919716]\n",
      "Score: 0.01879842, Weights: [0.07390478 0.03224269 0.00897177 0.88488076]\n",
      "Score: 0.01859542, Weights: [1.38777878e-17 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      "Score: 0.0025579, Weights: [0.36855318 0.08193929 0.30820334 0.24130419]\n",
      "Score: 0.02318307, Weights: [5.16987944e-26 2.87532889e-01 6.74070470e-02 6.45060064e-01]\n",
      "Score: 0.00897447, Weights: [0.21531843 0.36531287 0.12147199 0.2978967 ]\n",
      "Score: 0.00356815, Weights: [0.80267112 0.         0.         0.19732888]\n",
      "Score: 0.00996843, Weights: [0.05967034 0.23835575 0.30805617 0.39391774]\n",
      "final ensemble oof score: 0.0156244312481648\n",
      "OOF log loss:  0.01431546355573548\n",
      "CPU times: user 7min 16s, sys: 1.98 s, total: 7min 18s\n",
      "Wall time: 7min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sub = pd.read_csv(DATA_DIR + 'sample_submission.csv')\n",
    "check_score = pd.read_csv(DATA_DIR + 'train_targets_scored.csv').drop(\"sig_id\", axis=1)\n",
    "\n",
    "np.random.seed(42)\n",
    "blend_train = []\n",
    "blend_test = []\n",
    "\n",
    "# out of fold prediction\n",
    "blend_train.append(svm1_oof)\n",
    "#blend_train.append(xgb1_oof)\n",
    "blend_train.append(lstm1_oof)\n",
    "blend_train.append(tabnet1_oof)\n",
    "blend_train.append(mlp1_oof)\n",
    "blend_train = np.array(blend_train)\n",
    "\n",
    "# submission scores\n",
    "blend_test.append(svm1_test)\n",
    "#blend_test.append(xgb1_test)\n",
    "blend_test.append(lstm1_test)\n",
    "blend_test.append(tabnet1_test)\n",
    "blend_test.append(mlp1_test)\n",
    "blend_test = np.array(blend_test)\n",
    "\n",
    "total_scores = []\n",
    "for i in range(len(target_feats)):\n",
    "    def log_loss_func(weights):\n",
    "        final_prediction = 0\n",
    "        for weight, prediction in zip(weights, blend_train):\n",
    "            final_prediction += weight * prediction[:,i]\n",
    "        return log_loss(np.ravel(fn_targets[:,i]), np.ravel(final_prediction))\n",
    "    \n",
    "    best_score = np.inf\n",
    "    best_weights = [0] * len(blend_train)\n",
    "    for k in range(20):\n",
    "        starting_values = np.random.rand(len(blend_train))\n",
    "        starting_values /= sum(starting_values)\n",
    "        bounds = [(0, 1)] * len(blend_train)\n",
    "        cons = ({'type': 'eq', 'fun': lambda x:  1 - sum(x)}) \n",
    "            \n",
    "        res = minimize(log_loss_func,\n",
    "                   starting_values,\n",
    "                   method='SLSQP',\n",
    "                   bounds=bounds,\n",
    "                   constraints = cons) \n",
    "    \n",
    "        if best_score > res[\"fun\"]:\n",
    "            best_score = res[\"fun\"]\n",
    "            best_weights = res[\"x\"]\n",
    "        \n",
    "    valid_prediction = 0    \n",
    "    for weight, prediction in zip(best_weights, blend_train):\n",
    "        valid_prediction += weight * prediction[:,i]\n",
    "    print('Score: {}, Weights: {}'.format(round(res['fun'],8), res['x']))\n",
    "    total_scores.append(res['fun'])\n",
    "    check_score.loc[cons_train_index,target_feats[i]] = valid_prediction\n",
    "    \n",
    "    oof_test = 0\n",
    "    for weight, prediction in zip(best_weights, blend_test):\n",
    "        oof_test += weight * prediction[:,i]\n",
    "        \n",
    "    sub.loc[cons_test_index,target_feats[i]] = oof_test\n",
    "\n",
    "print(\"final ensemble oof score:\", np.mean(total_scores))\n",
    "print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(check_score)))\n",
    "\n",
    "sub.loc[noncons_test_index,target_feats] = 0\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2856.39243,
   "end_time": "2020-10-31T02:31:20.098527",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-31T01:43:43.706097",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "22efa5a9563b49f4a85dcba8b35a5c01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8d28379ce27147d9a9bad0c3569e88c3",
       "max": 206.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_baf55d66c3b043e3873bde0d11816325",
       "value": 206.0
      }
     },
     "36b8b2487d5b4f8f824bfc1b9ab7640c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d28379ce27147d9a9bad0c3569e88c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b34459da4ad74056932e329e9903a81f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b773bd57c2e447cfa599ab4f56c95dfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_22efa5a9563b49f4a85dcba8b35a5c01",
        "IPY_MODEL_ca575dd454c44979b1861a6aa3ac3964"
       ],
       "layout": "IPY_MODEL_b34459da4ad74056932e329e9903a81f"
      }
     },
     "baf55d66c3b043e3873bde0d11816325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "ca575dd454c44979b1861a6aa3ac3964": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_36b8b2487d5b4f8f824bfc1b9ab7640c",
       "placeholder": "",
       "style": "IPY_MODEL_d5d7ea8fa4ab4fc1a9da2bf42a18783a",
       "value": " 206/206 [08:56&lt;00:00,  2.60s/it]"
      }
     },
     "d5d7ea8fa4ab4fc1a9da2bf42a18783a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
